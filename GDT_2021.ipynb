{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "GDT_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EyF6ZVwMst_p",
        "66H3ZKixtDdQ",
        "_ls6LXB6uPwx",
        "i0MthZWIo98T",
        "26U6tybzg0cI",
        "t6O-_pJmg4Bg",
        "AJ1cYQypOfW1",
        "QU-hds4y1d1O",
        "zcn5tbaT0Gim"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25kJlnk0WmYX"
      },
      "source": [
        "# **Unreported Curtailment Analysis**\n",
        "\n"
      ],
      "id": "25kJlnk0WmYX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPuAiBZtsZ16"
      },
      "source": [
        "## Data loading and imports"
      ],
      "id": "zPuAiBZtsZ16"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjT_LzcJs5H_"
      },
      "source": [
        "### Imports"
      ],
      "id": "VjT_LzcJs5H_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izr5nEWYWg1Q",
        "outputId": "31082d57-bf8f-4e81-dd3d-5fd8ac88e2c6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install  pickle5\n",
        "\n",
        "import pickle5 as pickle\n",
        "import xlwt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from scipy import stats\n",
        "from datetime import datetime, timedelta\n",
        "from IPython.display import display, clear_output, HTML\n",
        "from sklearn.feature_selection import mutual_info_classif"
      ],
      "id": "izr5nEWYWg1Q",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting pickle5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/4c/5c4dd0462c8d3a6bc4af500a6af240763c2ebd1efdc736fc2c946d44b70a/pickle5-0.0.11.tar.gz (132kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 7.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp37-cp37m-linux_x86_64.whl size=219271 sha256=f98fc9752773eb9e297a64ed9ec53c67f70189ad48d2cfb078f03864a18cc801\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/90/95/f889ca4aa8b0e0c7f21c8470b6f5d6032f0390a3a141a9a3bd\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyF6ZVwMst_p"
      },
      "source": [
        "### Definitions (paths, parameters...)"
      ],
      "id": "EyF6ZVwMst_p"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVHDB7sPs_gm"
      },
      "source": [
        "root = 'drive/MyDrive/gdt data/'\n",
        "eventfile = root+'2021_GDT_Warning_Events.pkl'\n",
        "curtailmentfile = root+'2021_GDT_curtailment.pkl'\n",
        "setpointfile = root+'2021_GDT_setpoint.pkl'\n",
        "windfile = root+'2021_GDT_wind.pkl'\n",
        "alarmfile = root+'2021_GDT_alarms.pkl'\n",
        "\n",
        "# Thomas' files for validation\n",
        "Val_GDT004 = root+'GDT004_2020_now'\n",
        "Val_GDT005 = root+'GDT005_2020_now'\n",
        "Val_GDT022 = root+'GDT022_2020_now'\n",
        "Val_GDT024 = root+'GDT024_2020_now'\n",
        "Val_GDT025 = root+'GDT025_2020_now'"
      ],
      "id": "zVHDB7sPs_gm",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66H3ZKixtDdQ"
      },
      "source": [
        "### loading data"
      ],
      "id": "66H3ZKixtDdQ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oefgh7VdDbTt"
      },
      "source": [
        "with open(setpointfile, \"rb\") as fh:\n",
        "  SCADA_setpoint = pickle.load(fh)\n",
        "\n",
        "with open(eventfile, \"rb\") as fh:\n",
        "  turbine_events = pickle.load(fh)\n",
        "\n",
        "with open(curtailmentfile, \"rb\") as fh:\n",
        "  curtailment_reports = pickle.load(fh)\n",
        "\n",
        "with open(windfile, \"rb\") as fh:\n",
        "  SCADA_wind = pickle.load(fh)\n",
        "\n",
        "with open(alarmfile, \"rb\") as fh:\n",
        "  turbine_alarms = pickle.load(fh)"
      ],
      "id": "oefgh7VdDbTt",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P_69mtoxiUA"
      },
      "source": [
        "with open(Val_GDT004, \"rb\") as fh:\n",
        "  Val_GDT004 = pickle.load(fh)\n",
        "with open(Val_GDT005, \"rb\") as fh:\n",
        "  Val_GDT005 = pickle.load(fh)\n",
        "with open(Val_GDT022, \"rb\") as fh:\n",
        "  Val_GDT022 = pickle.load(fh)\n",
        "with open(Val_GDT024, \"rb\") as fh:\n",
        "  Val_GDT024 = pickle.load(fh)\n",
        "with open(Val_GDT025, \"rb\") as fh:\n",
        "  Val_GDT025 = pickle.load(fh)"
      ],
      "id": "2P_69mtoxiUA",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5NtlciMtTSs"
      },
      "source": [
        "if 'Querydate' in curtailment_reports:\n",
        "  curtailment_reports = curtailment_reports.drop(['Querydate', 'From_Local', 'To_Local', 'Duration', 'Comment', 'Id', 'LostProduction', 'Park', 'Production', 'ProductionLostTotal', 'ProductionTotal'], axis = 1)\n",
        "if 'From_UTC' in curtailment_reports:\n",
        "  # Rounding to closest 10 mins is a possible source of model bias\n",
        "  curtailment_reports['From'] = curtailment_reports['From_UTC'].dt.floor('10min')\n",
        "  curtailment_reports['To'] = curtailment_reports['To_UTC'].dt.round('10min')\n",
        "  curtailment_reports = curtailment_reports.drop(['From_UTC', 'To_UTC'], axis=1)"
      ],
      "id": "Y5NtlciMtTSs",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHXz8ztdQZ9y"
      },
      "source": [
        "turbine_alarms['ErrorType'] = 'Alarm'\n",
        "if 'Unit' in turbine_alarms:\n",
        "  turbine_alarms['Turbine'] = turbine_alarms['Unit']\n",
        "  turbine_alarms = turbine_alarms.drop(['Unit'], axis=1)\n",
        "\"\"\"\n",
        "if 'From_Floor' in turbine_alarms:\n",
        "  turbine_alarms['From'] = turbine_alarms['From_Floor']\n",
        "  turbine_alarms['To'] = turbine_alarms['To_Floor']\n",
        "  turbine_alarms = turbine_alarms.drop(['From_Floor', 'To_Floor'], axis=1)\n",
        "\"\"\"\n",
        "if 'From_UTC' in turbine_alarms:\n",
        "  turbine_alarms['From'] = turbine_alarms['From_UTC'].dt.floor('10min') #possible cause for missed correlations if curtailment triggers shortly after event\n",
        "  turbine_alarms['To'] = turbine_alarms['To_UTC'].dt.round('10min') # round should alleviate the above-stated problem\n",
        "  turbine_alarms = turbine_alarms.drop(['From_UTC', 'To_UTC'], axis=1)\n",
        "\n",
        "if 'AlarmTxt' in turbine_alarms:\n",
        "  turbine_alarms['Text'] = turbine_alarms['AlarmTxt']\n",
        "  turbine_alarms = turbine_alarms.drop(['AlarmTxt'], axis=1)\n",
        "\n",
        "if 'AlarmCode' in turbine_alarms:\n",
        "  turbine_alarms['ErrorCode'] = turbine_alarms['AlarmCode']\n",
        "  turbine_alarms = turbine_alarms.drop(['AlarmCode'], axis=1)\n"
      ],
      "id": "gHXz8ztdQZ9y",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37ed209d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87a01786-c26c-44d7-e5f6-ea30b521b170"
      },
      "source": [
        "rename = [col for col in SCADA_setpoint.columns if 'WTUR11_WSpt_val_max' in col]\n",
        "\n",
        "print('turbine events length:', len(turbine_events))\n",
        "print('turbine alarms length:', len(turbine_alarms))\n",
        "\n",
        "\n",
        "if len(rename) > 0:\n",
        "    df['Tag'] = 'WTUR11_WSpt_val'\n",
        "    df['Value'] = df['WTUR11_WSpt_val_max']\n",
        "    df['Timestamp'] = df['StartTime']\n",
        "\n",
        "if 'Unit' in turbine_events:\n",
        "  turbine_events['Turbine'] = turbine_events['Unit']\n",
        "  turbine_events = turbine_events.drop(['Unit'], axis=1)\n",
        "if 'From_Floor' in turbine_events:\n",
        "  turbine_events['From'] = turbine_events['From_Floor']\n",
        "  turbine_events['To'] = turbine_events['To_Floor']\n",
        "  turbine_events = turbine_events.drop(['From_Floor', 'To_Floor'], axis=1)\n",
        "if 'From_UTC' in turbine_events:\n",
        "  turbine_events['From'] = turbine_events['From_UTC'].dt.floor('10min') #possible cause for missed correlations if curtailment triggers shortly after event\n",
        "  turbine_events['To'] = turbine_events['To_UTC'].dt.round('10min') # round should alleviate the above-stated problem\n",
        "  turbine_events = turbine_events.drop(['From_UTC', 'To_UTC'], axis=1)\n",
        "if 'ID' in turbine_events:\n",
        "  turbine_events = turbine_events.drop(['ID', 'Source', 'CustomText', 'Wallclock_UTC', 'CommFailure', 'MayTrigger', 'RemoteID', 'Created_UTC', 'ErrorListID', 'RowLastUpdated'], axis=1)\n",
        "turbine_events =  pd.concat([turbine_events ,turbine_alarms], ignore_index=True) #merge alarms and events into one dataframe\n",
        "\n",
        "print('length after merging:', len(turbine_events))"
      ],
      "id": "37ed209d",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "turbine events length: 87609\n",
            "turbine alarms length: 3415\n",
            "length after merging: 91024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVJ3igtzSX6Z",
        "outputId": "3ab765a0-282a-4ea5-e9a3-82230361244c"
      },
      "source": [
        "long_events = (turbine_events['To'] - turbine_events['From']  < pd.Timedelta(value=31, unit='days'))\n",
        "print('Number of events that exceed one month: ', len(long_events[long_events == False]))\n",
        "turbine_events = turbine_events[long_events]\n",
        "print('Remaining length: ', len(turbine_events))"
      ],
      "id": "mVJ3igtzSX6Z",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of events that exceed one month:  293\n",
            "Remaining length:  90731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOOdfF12Xm8a"
      },
      "source": [
        "Removing events that are longer than one month."
      ],
      "id": "mOOdfF12Xm8a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VLBJQ36uGLh"
      },
      "source": [
        "## Model functions: information gathering and rule-based alaysis"
      ],
      "id": "3VLBJQ36uGLh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ls6LXB6uPwx"
      },
      "source": [
        "### Utility"
      ],
      "id": "_ls6LXB6uPwx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOdnHeIMufDZ"
      },
      "source": [
        "def navigator(*argv, function=None):\n",
        "    \"\"\"\n",
        "    Small CLI-style function that helps to sequentially execute commands \n",
        "    on user input.\n",
        "    type \"y\" to continue and \"n\" to exit\n",
        "\n",
        "    Args:\n",
        "        function to be executed, takes an integer as parameter\n",
        "\n",
        "    Returns:\n",
        "        Nothing\n",
        "    \"\"\"\n",
        "\n",
        "    counter = 0\n",
        "    while(True):\n",
        "      print('index ', counter, ' ...continue?')\n",
        "      val = input()\n",
        "      if val == 'n':\n",
        "        break\n",
        "      else:\n",
        "        function(argv, i=counter)\n",
        "      counter += 1\n",
        "\n",
        "def within_margin(target_value, comparison_value, maxval: int, difference_ratio=0.02):\n",
        "    \"\"\"\n",
        "    Evaluate whether the target value falls into a interval around the\n",
        "    comparison value. The interval is defined as percentage of the maximum value\n",
        "    for the dataset. This is used to determine oscillating values pertaining to\n",
        "    the same curtailment event (controller curtailment) and gradual change\n",
        "    as opposed to constant values (technician curtailment). \n",
        "\n",
        "    Args:\n",
        "        target_value: the value or vector of values being compared/checked\n",
        "        comparison value: the value or vector of values \n",
        "        at the center of the interval\n",
        "        maxval: the highest value in the dataset\n",
        "        difference_ratio: the ratio that defines the interval\n",
        "\n",
        "    Returns:\n",
        "        True if target_value is close enough to comparison_value. False othewise.\n",
        "    \"\"\"\n",
        "\n",
        "    return np.abs(target_value-comparison_value) < (maxval * difference_ratio )\n",
        "\n",
        "def progress(value: float, max=100):\n",
        "    \"\"\"Display progress bar for execution\n",
        "\n",
        "    Args:\n",
        "        value: progress value\n",
        "        max: maximum value of progress (default 100)\n",
        "\n",
        "    Returns:\n",
        "        Html progress bar\n",
        "\n",
        "    \"\"\"\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))\n",
        "\n",
        "def during(start1: pd.Timestamp, end1: pd.Timestamp, end2: pd.Timestamp):\n",
        "    \"\"\"Check whether event 1 is happening during event 2 \n",
        "    (check for positive overlap of the two events)\n",
        "\n",
        "    Args:\n",
        "        start1: Timestamp indicating the start of event 1\n",
        "        end1: Timestamp indicating the end of event 1\n",
        "        end2: Timestamp indicating the end of event 2\n",
        "\n",
        "    Returns:\n",
        "        True if event 2 happens (partly) during event 1, False otherwise\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    latest = max(start1, end2)\n",
        "    earliest = min(end1, end2)\n",
        "    delta = pd.Timedelta((earliest - latest)).total_seconds()\n",
        "    \n",
        "    if delta < 0:\n",
        "        return False\n",
        "    return True"
      ],
      "id": "kOdnHeIMufDZ",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0MthZWIo98T"
      },
      "source": [
        "### Reflections and statistics about turbine data"
      ],
      "id": "i0MthZWIo98T"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R50ateO4zgte",
        "outputId": "5e10b720-9d58-429c-ea6e-bf48e64688ac"
      },
      "source": [
        "len(SCADA_setpoint['Turbine'].unique())"
      ],
      "id": "R50ateO4zgte",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDzIDGMmz4-M"
      },
      "source": [
        "Number of turbines in park."
      ],
      "id": "WDzIDGMmz4-M"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lirgkUBpRJb",
        "outputId": "231d6216-a6ce-4aeb-bc71-cca1694ba173"
      },
      "source": [
        "max_val = SCADA_setpoint['Value'].max()\n",
        "max_val"
      ],
      "id": "1lirgkUBpRJb",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3600.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH_RPcafpVvd"
      },
      "source": [
        "rated power of the Siemens turbines deployed at GDT is 3600 kW. Cut-in wind speed : 3.5 m/s, Rated-end: 24 m/s, Cut-out: 25 m/s (High wind ride through suspected, but often not reported)"
      ],
      "id": "eH_RPcafpVvd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJRHoXXfp1Qi",
        "outputId": "a3415c30-c47e-4472-860e-87fa0301a4ff"
      },
      "source": [
        "avg_events = turbine_events.groupby(\"Turbine\", axis=0)[\"ErrorCode\"].count().mean()\n",
        "print(avg_events)"
      ],
      "id": "zJRHoXXfp1Qi",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1134.1375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjXsH4WZqi6m"
      },
      "source": [
        "Average number of events (alarms included) per Turbine."
      ],
      "id": "TjXsH4WZqi6m"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCFnucCgyXl7",
        "outputId": "6db3658e-dbda-484b-b740-3bf88415f516"
      },
      "source": [
        "avg_unique_events = turbine_events.groupby(\"Turbine\", axis=0)[\"ErrorCode\"].nunique().mean()\n",
        "avg_unique_events"
      ],
      "id": "rCFnucCgyXl7",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65.425"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UihAE6pby5xc"
      },
      "source": [
        "Average number of unique event codes per Turbine."
      ],
      "id": "UihAE6pby5xc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVusOF03nJMZ",
        "outputId": "3be7ebf7-6196-450b-f6bc-4a0d180cb43b"
      },
      "source": [
        "print(len(curtailment_reports), ' reported curtailments', ' between ', curtailment_reports.From.min(), ' and ', curtailment_reports['To'].max())"
      ],
      "id": "bVusOF03nJMZ",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39  reported curtailments  between  2021-01-03 12:20:00  and  2021-05-19 18:10:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYUH4vqyrFcP",
        "outputId": "a0a33f62-e8f5-4fdc-ed9f-4aa6d483d5ab"
      },
      "source": [
        "avg_len_data = SCADA_wind.groupby(\"Turbine\", axis=0)['Value'].count().mean()\n",
        "print(\"average number of data points per turbine: \", avg_len_data )\n",
        "avg_number_of_data_points_below_cut_in = SCADA_wind[SCADA_wind['Value'] <= 3.5].groupby(\"Turbine\", axis=0)['Value'].count().mean()\n",
        "print(\"average number of data points below cut in power per turbine: \", round(avg_number_of_data_points_below_cut_in,2))\n",
        "print(\"percentage of data points below cut in: \", round(avg_number_of_data_points_below_cut_in/avg_len_data*100, 4), \"%\")\n",
        "avg_number_of_data_points_above_rated = SCADA_wind[SCADA_wind['Value'] >= 24].groupby(\"Turbine\", axis=0)['Value'].count().mean()\n",
        "print(\"average number of data points above rated power per turbine: \", round(avg_number_of_data_points_above_rated, 4))\n",
        "print(\"percentage of data points in possible HWRT zone: \", round(avg_number_of_data_points_above_rated/avg_len_data*100, 4), \"%\")"
      ],
      "id": "qYUH4vqyrFcP",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average number of data points per turbine:  16672.1625\n",
            "average number of data points below cut in power per turbine:  1794.97\n",
            "percentage of data points below cut in:  10.7663 %\n",
            "average number of data points above rated power per turbine:  36.1538\n",
            "percentage of data points in possible HWRT zone:  0.2169 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gckrMlpBB9v"
      },
      "source": [
        "Even though the model has a rule to flag potential instances of High Wind Ride Through, this has a minor impact, as the occurences of very high windspeed are merely **0.2%** of the data"
      ],
      "id": "_gckrMlpBB9v"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqeHN7kWk_nb",
        "outputId": "400098cd-c3d4-4d30-92e1-d1238027bb36"
      },
      "source": [
        "setpoint = SCADA_setpoint.pivot_table(index=['Timestamp'], columns=['Turbine'])\n",
        "\n",
        "highest_number_of_nan = setpoint.isna().sum().max()\n",
        "average_number_of_nan = setpoint.isna().sum().mean()\n",
        "avg_num_of_datapoint = setpoint.count().mean()\n",
        "print('highest number of nans after regrouping into timeseries: ', highest_number_of_nan)\n",
        "print('average number of nans after regrouping into timeseries: ', average_number_of_nan)\n",
        "print('average number of datapoints in total: ', avg_num_of_datapoint)\n",
        "print('As percentages. avg: ', round((average_number_of_nan/avg_num_of_datapoint)*100, 2), '%. max: ', round((highest_number_of_nan/avg_num_of_datapoint)*100, 2), '%')\n",
        "\n",
        "setpoint = setpoint.stack().swaplevel(i='Turbine', j='Timestamp')\n",
        "print('Length of turbine dataframe after stacking: ', len(setpoint.xs('GDT058', level='Turbine')), 'compared to max length: ', SCADA_setpoint.groupby(\"Turbine\", axis=0)['Value'].count().max())\n"
      ],
      "id": "qqeHN7kWk_nb",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "highest number of nans after regrouping into timeseries:  2841\n",
            "average number of nans after regrouping into timeseries:  417.3875\n",
            "average number of datapoints in total:  16673.6125\n",
            "As percentages. avg:  2.5 %. max:  17.04 %\n",
            "Length of turbine dataframe after stacking:  14250 compared to max length:  17078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOt9vEMr2pDe"
      },
      "source": [
        "Regrouping SCADA tags into a time series represents a big challenge: how to deal with NaN values?\n",
        "\n",
        "In theory, the **average number of NaN's is accetably low -  2.5%** of values are NaN. However, most NaN values are **stacked and concentrated** in data of Turbines with lots of missing data. In primis, **17% of the data for Turbine 58 are NaN values**.\n",
        "\n",
        "Fortunately, this is not a problem for Turbine-specific operations, as the NaN rows are removed when extracting a cross-section from the pivot table.\n",
        "\n",
        "For aggregated park operations, however, this will be a major issue.  Currently, NaN values are **backfilled** with the next valid value. This approach might have to be reevaluated. "
      ],
      "id": "sOt9vEMr2pDe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gV193e1CyLX"
      },
      "source": [
        "TODO: find the spot with high wind outliers again and document it."
      ],
      "id": "9gV193e1CyLX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bE8czQ5too6f",
        "outputId": "780444ed-eb14-48ba-c0a5-29ecb4a2c225"
      },
      "source": [
        "turbine_events['Duration'] = turbine_events.To - turbine_events.From\n",
        "turbine_events[turbine_events.ErrorCode == 5112].sort_values(by=['Duration'], ascending=False).head(10)"
      ],
      "id": "bE8czQ5too6f",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ErrorCode</th>\n",
              "      <th>Text</th>\n",
              "      <th>ErrorType</th>\n",
              "      <th>Turbine</th>\n",
              "      <th>From</th>\n",
              "      <th>To</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76643</th>\n",
              "      <td>5112</td>\n",
              "      <td>Gridvolt.&lt;lower limit3</td>\n",
              "      <td>Alarm</td>\n",
              "      <td>GDT018</td>\n",
              "      <td>2021-01-07 15:10:00</td>\n",
              "      <td>2021-01-14 15:00:00</td>\n",
              "      <td>6 days 23:50:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76990</th>\n",
              "      <td>5112</td>\n",
              "      <td>Gridvolt.&lt;lower limit3</td>\n",
              "      <td>Alarm</td>\n",
              "      <td>GDT016</td>\n",
              "      <td>2021-01-09 16:00:00</td>\n",
              "      <td>2021-01-14 13:30:00</td>\n",
              "      <td>4 days 21:30:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81523</th>\n",
              "      <td>5112</td>\n",
              "      <td>Gridvolt.&lt;lower limit3</td>\n",
              "      <td>Alarm</td>\n",
              "      <td>GDT015</td>\n",
              "      <td>2021-01-04 03:40:00</td>\n",
              "      <td>2021-01-08 13:50:00</td>\n",
              "      <td>4 days 10:10:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5501</th>\n",
              "      <td>5112</td>\n",
              "      <td>Gridvolt.&lt;lower limit3</td>\n",
              "      <td>Alarm</td>\n",
              "      <td>GDT019</td>\n",
              "      <td>2021-04-23 06:30:00</td>\n",
              "      <td>2021-04-26 10:00:00</td>\n",
              "      <td>3 days 03:30:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5771</th>\n",
              "      <td>5112</td>\n",
              "      <td>Gridvolt.&lt;lower limit3</td>\n",
              "      <td>Alarm</td>\n",
              "      <td>GDT033</td>\n",
              "      <td>2021-04-22 17:40:00</td>\n",
              "      <td>2021-04-25 13:30:00</td>\n",
              "      <td>2 days 19:50:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79689</th>\n",
              "      <td>5112</td>\n",
              "      <td>Gridvolt.&lt;lower limit3</td>\n",
              "      <td>Alarm</td>\n",
              "      <td>GDT017</td>\n",
              "      <td>2021-01-07 12:20:00</td>\n",
              "      <td>2021-01-09 16:10:00</td>\n",
              "      <td>2 days 03:50:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15228</th>\n",
              "      <td>5112</td>\n",
              "      <td>Gridvolt.&lt;lower limit3</td>\n",
              "      <td>Alarm</td>\n",
              "      <td>GDT017</td>\n",
              "      <td>2021-04-13 13:10:00</td>\n",
              "      <td>2021-04-15 12:40:00</td>\n",
              "      <td>1 days 23:30:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14191</th>\n",
              "      <td>5112</td>\n",
              "      <td>Gridvolt.&lt;lower limit3</td>\n",
              "      <td>Alarm</td>\n",
              "      <td>GDT017</td>\n",
              "      <td>2021-04-15 12:40:00</td>\n",
              "      <td>2021-04-17 10:00:00</td>\n",
              "      <td>1 days 21:20:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79793</th>\n",
              "      <td>5112</td>\n",
              "      <td>Gridvolt.&lt;lower limit3</td>\n",
              "      <td>Alarm</td>\n",
              "      <td>GDT016</td>\n",
              "      <td>2021-01-07 20:40:00</td>\n",
              "      <td>2021-01-09 14:40:00</td>\n",
              "      <td>1 days 18:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76892</th>\n",
              "      <td>5112</td>\n",
              "      <td>Gridvolt.&lt;lower limit3</td>\n",
              "      <td>Alarm</td>\n",
              "      <td>GDT037</td>\n",
              "      <td>2021-01-13 00:20:00</td>\n",
              "      <td>2021-01-14 13:50:00</td>\n",
              "      <td>1 days 13:30:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ErrorCode                    Text  ...                  To        Duration\n",
              "76643       5112  Gridvolt.<lower limit3  ... 2021-01-14 15:00:00 6 days 23:50:00\n",
              "76990       5112  Gridvolt.<lower limit3  ... 2021-01-14 13:30:00 4 days 21:30:00\n",
              "81523       5112  Gridvolt.<lower limit3  ... 2021-01-08 13:50:00 4 days 10:10:00\n",
              "5501        5112  Gridvolt.<lower limit3  ... 2021-04-26 10:00:00 3 days 03:30:00\n",
              "5771        5112  Gridvolt.<lower limit3  ... 2021-04-25 13:30:00 2 days 19:50:00\n",
              "79689       5112  Gridvolt.<lower limit3  ... 2021-01-09 16:10:00 2 days 03:50:00\n",
              "15228       5112  Gridvolt.<lower limit3  ... 2021-04-15 12:40:00 1 days 23:30:00\n",
              "14191       5112  Gridvolt.<lower limit3  ... 2021-04-17 10:00:00 1 days 21:20:00\n",
              "79793       5112  Gridvolt.<lower limit3  ... 2021-01-09 14:40:00 1 days 18:00:00\n",
              "76892       5112  Gridvolt.<lower limit3  ... 2021-01-14 13:50:00 1 days 13:30:00\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhBWeZLbpAuf"
      },
      "source": [
        "Event **5112** has been investigated in an ad-hoc request by the Analytics team and has shown some **connection to curtailment**. Unfortunately, the longest duration event (almost 7 days) on turbine GDT018 has **no setpoint data at all for that period**. **Production is also zero** for that period."
      ],
      "id": "QhBWeZLbpAuf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LpU1Q8a8pdzn",
        "outputId": "f348abc8-b79f-4779-cd0c-0db719c63c0f"
      },
      "source": [
        "SCADA_setpoint[SCADA_setpoint.Turbine == 'GDT015'].sort_values(by='Timestamp').set_index(['Timestamp']).loc[\"2021-01-04 03:30:00\":\"2021-01-08 14:00:00\"]"
      ],
      "id": "LpU1Q8a8pdzn",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Turbine</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-01-04 03:30:00</th>\n",
              "      <td>1573.0</td>\n",
              "      <td>WTUR11_WSpt_val</td>\n",
              "      <td>GDT015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-01-04 03:40:00</th>\n",
              "      <td>1665.0</td>\n",
              "      <td>WTUR11_WSpt_val</td>\n",
              "      <td>GDT015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-01-04 03:50:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>WTUR11_WSpt_val</td>\n",
              "      <td>GDT015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-01-04 04:00:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>WTUR11_WSpt_val</td>\n",
              "      <td>GDT015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-01-04 04:10:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>WTUR11_WSpt_val</td>\n",
              "      <td>GDT015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-01-04 04:20:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>WTUR11_WSpt_val</td>\n",
              "      <td>GDT015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-01-04 04:30:00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>WTUR11_WSpt_val</td>\n",
              "      <td>GDT015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-01-08 13:40:00</th>\n",
              "      <td>3600.0</td>\n",
              "      <td>WTUR11_WSpt_val</td>\n",
              "      <td>GDT015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-01-08 13:50:00</th>\n",
              "      <td>124.0</td>\n",
              "      <td>WTUR11_WSpt_val</td>\n",
              "      <td>GDT015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-01-08 14:00:00</th>\n",
              "      <td>3600.0</td>\n",
              "      <td>WTUR11_WSpt_val</td>\n",
              "      <td>GDT015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Value              Tag Turbine\n",
              "Timestamp                                           \n",
              "2021-01-04 03:30:00  1573.0  WTUR11_WSpt_val  GDT015\n",
              "2021-01-04 03:40:00  1665.0  WTUR11_WSpt_val  GDT015\n",
              "2021-01-04 03:50:00     0.0  WTUR11_WSpt_val  GDT015\n",
              "2021-01-04 04:00:00     0.0  WTUR11_WSpt_val  GDT015\n",
              "2021-01-04 04:10:00     0.0  WTUR11_WSpt_val  GDT015\n",
              "2021-01-04 04:20:00     0.0  WTUR11_WSpt_val  GDT015\n",
              "2021-01-04 04:30:00     0.0  WTUR11_WSpt_val  GDT015\n",
              "2021-01-08 13:40:00  3600.0  WTUR11_WSpt_val  GDT015\n",
              "2021-01-08 13:50:00   124.0  WTUR11_WSpt_val  GDT015\n",
              "2021-01-08 14:00:00  3600.0  WTUR11_WSpt_val  GDT015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0BNVTlhpojn"
      },
      "source": [
        "As shown here for turbine GDT015, The timestamps where event 5112 is active have no discernable pattern: the setpoint is 0 at times and at full rated power at others."
      ],
      "id": "Q0BNVTlhpojn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDQ2FP4x3su_"
      },
      "source": [
        "### Turbine specific functions"
      ],
      "id": "rDQ2FP4x3su_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26U6tybzg0cI"
      },
      "source": [
        "#### Event-related\n"
      ],
      "id": "26U6tybzg0cI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8RYDXLlg74v"
      },
      "source": [
        "def expand_dummy_event_columns(turbine_curtailments: pd.DataFrame, turbine_events: pd.DataFrame, missing_as_na=False):\n",
        "  \"\"\"\n",
        "  Add a dummy column for each event code to turbine curtailment containing the\n",
        "  overlap ratio. 0 for non-ovelapping.\n",
        "\n",
        "  Args:\n",
        "      turbine_curtailments:  DataFrame containing detected curtailment events\n",
        "      per turbine.\n",
        "      turbine_events: DataFrame containing events and alarms for one turbine.\n",
        "      missing_as_na: if True, exapnded dataframe will be filled with na's, \n",
        "      otherwise with zeroes\n",
        "\n",
        "  Returns:\n",
        "      Adds a column for each event code and returns modified dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  filler = np.nan if missing_as_na else 0.\n",
        "  event_codes = turbine_events.ErrorCode.unique()\n",
        "  def create_list(event_codes):\n",
        "    for code in event_codes:\n",
        "      yield (str(code) + '_Curtailment_Coverage')\n",
        "      yield (str(code) + '_Coverage_Duration') \n",
        "      yield (str(code) + '_Coverage_Ratio')\n",
        "\n",
        "\n",
        "\n",
        "  if isinstance(turbine_curtailments, list):   \n",
        "    for curtailment in range(len(turbine_curtailments)):\n",
        "      # Need to generate list in every loop iteration, otherwise it \"runs out\n",
        "      # of objects\"\n",
        "      col_list = create_list(event_codes) \n",
        "\n",
        "      extra_cols = pd.DataFrame(filler, index=turbine_curtailments[curtailment].index, columns=list(col_list))\n",
        "\n",
        "      turbine_curtailments[curtailment] = pd.concat([turbine_curtailments[curtailment], extra_cols], axis=1)\n",
        "\n",
        "  elif isinstance(turbine_curtailments, pd.DataFrame):\n",
        "\n",
        "      col_list = create_list(event_codes)\n",
        "\n",
        "      extra_cols = pd.DataFrame(filler, index=turbine_curtailments.index, columns=list(col_list))\n",
        "\n",
        "      turbine_curtailments = pd.concat([turbine_curtailments, extra_cols], axis=1)\n",
        "  else:\n",
        "    print(\"Error: object to expand is neither a list of curtailments nor a single turbine curtailment dataframe!\")\n",
        "\n",
        "  return turbine_curtailments\n",
        "\n",
        "\n",
        "def efficient_event_overlap_calculation(turbine_curtailments: pd.DataFrame, single_turbine_events: pd.DataFrame):\n",
        "  # TODO: investigate and fix possible bug when multiple events with the same \n",
        "  # code overlap a zero-duration curtailment window.\n",
        "\n",
        "  \"\"\"\n",
        "  Evaluate overlap ratios between events and detected curtailment. 0 means no\n",
        "  overlap.\n",
        "\n",
        "  Same caveats as with efficient_curtailment_overlap_calculation apply.\n",
        "\n",
        "  Args:\n",
        "      turbine_curtailments:  DataFrame containing detected curtailment events\n",
        "      per turbine.\n",
        "      turbine_events: DataFrame containing events and alarms for one turbine.\n",
        "\n",
        "  Returns:\n",
        "      Void. Adds three columns for each event code containing the ratio of overlap\n",
        "      of the event by curtailment, the ratio of overlap of the curtailment by the\n",
        "      event and the duration of this overlap.\n",
        "\n",
        "      NB: In previous versions of this project both the ratio of overlap for the\n",
        "      event by the curtailment and for the curtailment by the event were\n",
        "      determined. There is a case to be made that the latter might be an \n",
        "      interesting metric too: currently, a very short event that happens during \n",
        "      curtailment will have a high overlap ratio, but explain very little about \n",
        "      the curtailment event.\n",
        "\n",
        "      Deprecated: \n",
        "        --Adds two columns: list of overlapping events and list of ratios.--\n",
        "        Now replaced by dummy columns\n",
        "  \"\"\"\n",
        "\n",
        "  if turbine_curtailments.columns.str.contains(pat = 'Coverage').any():\n",
        "\n",
        "    for detected_turbine_curtailment in turbine_curtailments.iloc:\n",
        "      overlappers = single_turbine_events[(~(single_turbine_events.index > detected_turbine_curtailment.End) & ~(single_turbine_events.To < detected_turbine_curtailment.name))]\n",
        "      for event in overlappers.iloc:\n",
        "        code = str(event['ErrorCode'])\n",
        "        coverage = pd.Timedelta(min(detected_turbine_curtailment.End, event.To)-max(detected_turbine_curtailment.name, event.name)).total_seconds()\n",
        "        curtailment_duration = pd.Timedelta(detected_turbine_curtailment.End-detected_turbine_curtailment.name).total_seconds()\n",
        "        if curtailment_duration == 0:\n",
        "          turbine_curtailments.at[detected_turbine_curtailment.name, code + '_Curtailment_Coverage'] = 1.\n",
        "        else:\n",
        "          turbine_curtailments.at[detected_turbine_curtailment.name, code + '_Curtailment_Coverage'] = (coverage/curtailment_duration)\n",
        "\n",
        "        turbine_curtailments.at[detected_turbine_curtailment.name, code + '_Coverage_Duration'] += coverage\n",
        "\n",
        "        event_duration = pd.Timedelta(event.To-event.name).total_seconds()\n",
        "        if event_duration == 0:\n",
        "          turbine_curtailments.at[detected_turbine_curtailment.name, code + '_Coverage_Ratio'] = 1\n",
        "        else:\n",
        "          turbine_curtailments.at[detected_turbine_curtailment.name, code + '_Coverage_Ratio'] = coverage/event_duration\n",
        "        \n",
        "        \"\"\"\n",
        "        if code == '5112' and event_duration != 0 and curtailment_duration != 0:\n",
        "          display(detected_turbine_curtailment)\n",
        "          display(overlappers)\n",
        "          display(overlappers[overlappers.ErrorCode == 5112])\n",
        "          print(\"coverage \", coverage)\n",
        "          print(\"curtailment cov \", coverage/curtailment_duration)\n",
        "          print(\"coverage ratio> \", coverage/event_duration)\n",
        "          display(\"Curtailment coverage in output dataframe: \", turbine_curtailments.at[detected_turbine_curtailment.name, code + '_Curtailment_Coverage'])\n",
        "        \"\"\"\n",
        "\n",
        "  else:\n",
        "    print(\"please expand the columns first\")\n",
        "\n",
        "\n",
        "def delete_long_events(turbine_events: pd.DataFrame, turbine_curtailments: pd.DataFrame):\n",
        "  \"\"\"\n",
        "  Deletes all events in turbine_events that are longer than the longest curtailment\n",
        "\n",
        "  Args:\n",
        "      turbine_curtailments:  DataFrame containing detected curtailment events\n",
        "      per turbine.\n",
        "      turbine_events: DataFrame containing events and alarms for one turbine.\n",
        "\n",
        "  Returns:\n",
        "      trimmed DataFrame.\n",
        "  \"\"\"\n",
        "\n",
        "  names = SCADA_setpoint[\"Turbine\"].unique()\n",
        "  names = np.sort(names)\n",
        "  len_before = len(turbine_events)\n",
        "  for i in range(1):\n",
        "    a[i]['Duration'] = a[i].End - a[i].index\n",
        "    turbine_events = turbine_events[((turbine_events.To - turbine_events.From < a[i]['Duration'].max()) | (turbine_events.Turbine == names[i]))] \n",
        "  print('Deleted ', len_before-len(turbine_events), ' long duration events from turbine event DataFrame')\n",
        "  return turbine_events"
      ],
      "id": "a8RYDXLlg74v",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6O-_pJmg4Bg"
      },
      "source": [
        "#### Curtailment-related\n"
      ],
      "id": "t6O-_pJmg4Bg"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoZgRiq336-v"
      },
      "source": [
        "def high_wind_ride_through(current_turbine: pd.DataFrame, current_wind: pd.DataFrame) :\n",
        "    \"\"\"\n",
        "    Calculate whether for a certain timestamp high wind ride through is likely\n",
        "\n",
        "    Args:\n",
        "        current_turbine: DataFrame containing flagged data of one turbine\n",
        "        current_wind: DataFrame containing SCADA ambient wind data for one \n",
        "        turbine\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with column with wind flags\n",
        "    \"\"\"\n",
        "\n",
        "    current_wind = current_wind.set_index(['Timestamp'])\n",
        "    current_wind = current_wind.sort_index()\n",
        "\n",
        "    current_turbine['HWRT'] = (current_wind['Value'] > 24)\n",
        "\n",
        "\n",
        "    current_turbine = current_turbine.fillna(value={'HWRT': False})    \n",
        "    return current_turbine\n",
        "\n",
        "def technician_curtailment(current_turbine: pd.DataFrame):\n",
        "  \"\"\"\n",
        "  Evaluate whether a curtailment is technician curtailment\n",
        "\n",
        "  Args:\n",
        "      current_turbine: DataFrame containing flagged data of one turbine\n",
        "      current_wind: DataFrame containing SCADA ambient wind data for one \n",
        "      turbine\n",
        "\n",
        "  Returns:\n",
        "      DataFrame with column with wind flags\n",
        "  \"\"\"\n",
        "\n",
        "  previous_val = current_turbine['Value'].shift()\n",
        "  next_val = current_turbine['Value'].shift(-1)\n",
        "  after_next_val = current_turbine['Value'].shift(-1).shift(-1)\n",
        "\n",
        "  # Technician curtailment is active if the turbine is curtailed and the next two\n",
        "  # values are the exactly the same, or the previous one is exactly the same, as\n",
        "  # the current one\n",
        "  current_turbine['isTechnicianCurtailment'] = \\\n",
        "    current_turbine['isCurtailed'] & (((next_val == current_turbine['Value']) & \\\n",
        "    (after_next_val == current_turbine['Value'])) | \\\n",
        "    (previous_val == current_turbine['Value']))\n",
        "\n",
        "  return current_turbine\n",
        "\n",
        "\n",
        "def efficient_curtailment_overlap_calculation(turbine_curtailments: pd.DataFrame, curtailment_reports: pd.DataFrame, timeseries=False):\n",
        "  \"\"\"\n",
        "  Compare discovered curtailments with curtailment reports and add a column\n",
        "  containing a flag for whether there is overlap.\n",
        "\n",
        "  Overlap is calculated optimistically in favor of reported curtailments\n",
        "  if working with floored timestamps (as is the case with the default data \n",
        "  loading for this project). For example, a detected curtailment might end at\n",
        "  'xx-xx-xxxx 15-43-000' and a curtailment report might start at \n",
        "  'xx-xx-xxxx 15-47-000'; subsequently, both are floored to the closest 10-minute\n",
        "  interval at 'xx-xx-xxxx 15-40-000' and counted as overlapping.\n",
        "\n",
        "  Args:\n",
        "      turbine_curtailments:  DataFrame containing detected curtailment events\n",
        "      per turbine\n",
        "      curtailment_reports: DataFrame containing curtailment reports from\n",
        "      fact.CurtailmentNew\n",
        "      timeseries: Boolean. If True, will set end time to start time for time series.\n",
        "\n",
        "  Returns:\n",
        "      Void. Adds boolean column 'Reported' to turbine_curtailments.\n",
        "  \"\"\"\n",
        "  \n",
        "  curtailment_reports = curtailment_reports.sort_values(by=['From'])\n",
        "  curtailment_reports = curtailment_reports.set_index('From')\n",
        "  \n",
        "\n",
        "  iterator1 = turbine_curtailments.iterrows()\n",
        "  iterator2 = curtailment_reports.iterrows()\n",
        "  index1, row1 = next(iterator1)\n",
        "  index2, row2 = next(iterator2)\n",
        "  turbine_curtailments['Reported'] = False\n",
        "\n",
        "  # Only one iteration\n",
        "  while True:\n",
        "    try:\n",
        "      if timeseries:\n",
        "        range1 = pd.Interval(left=row1.name, right=row1.name)\n",
        "      else:\n",
        "        range1 = pd.Interval(left=row1.name, right=row1.End)\n",
        "      range2 = pd.Interval(left=row2.name, right=row2.To)\n",
        "      if range2.right < range1.left:\n",
        "        # no overlap. range2 before r1. advance iterator2\n",
        "        index2, row2 = next(iterator2)\n",
        "      elif range1.right < range2.left:\n",
        "        # no overlap. range1 before r2. advance iterator1\n",
        "        index1, row1 = next(iterator1)\n",
        "      else:\n",
        "        # overlap. overlap(row1, row2) must > 0 \n",
        "        turbine_curtailments.loc[index1, 'Reported'] = True\n",
        "        # determine whether to advance iterator1 or it2\n",
        "        if range1.right < range2.right:\n",
        "            # advance iterator1\n",
        "            index1, row1 = next(iterator1)\n",
        "        else:\n",
        "          # advance iterator2\n",
        "          index2, row2 = next(iterator2)\n",
        "    except StopIteration:\n",
        "      break\n",
        "\n",
        "\n",
        "def extract_curtailment_windows(SCADA_setpoint: pd.DataFrame, \n",
        "                                difference_ratio=0.1, \n",
        "                                count_zero_as_curtailment=False, \n",
        "                                additional_flags=False,\n",
        "                                fill_missing_data=False,\n",
        "                                SCADA_wind = None, \n",
        "                                curtailment_reports = None, \n",
        "                                turbine_events=None):\n",
        "  \"\"\"\n",
        "  Extract curtailment windows from SCADA per turbine.\n",
        "\n",
        "  Args:\n",
        "      SCADA_setpoint: DataFrame containing the setpoint signal\n",
        "\n",
        "      difference_ratio: ratio to determine maximum deviation after which\n",
        "      a setpoint change is considered new curtailment\n",
        "\n",
        "      additional_flags: if True, additional information such as high wind \n",
        "      ride through will be added, thus save iterations\n",
        "\n",
        "      count_zero_as_curtailment: if True, setpoint values of 0 and 1 will be\n",
        "      counted as curtailment\n",
        "\n",
        "      fill_missing_data: if True, missing setpoint values are filled with 0 for\n",
        "      all timestamps present for at least one turbine. Otherwise remaining\n",
        "      timestamps are treated as non-existing in single-turbine operations.\n",
        "\n",
        "      SCADA_Wind: ambient wind scada data, only needed if additional_flags is \n",
        "      True\n",
        "\n",
        "      curtailment_reports: Park curtailment reports, only necessary if \n",
        "      additional_flags is set\n",
        "\n",
        "      turbine_events: turbine event data for all turbines, only necessary if \n",
        "      additional_flags is set\n",
        "\n",
        "  Returns:\n",
        "      list of dataframes with curtailment events per turbine and list of\n",
        "      dataframes of flagged timeseries per turbine\n",
        "  \"\"\"\n",
        "\n",
        "  setpoint = SCADA_setpoint\n",
        "  max_val = setpoint['Value'].max()\n",
        "  if fill_missing_data:\n",
        "    setpoint = setpoint.pivot_table(index=['Timestamp'], columns=['Turbine'], fill_value=0)\n",
        "  else:\n",
        "    setpoint = setpoint.pivot_table(index=['Timestamp'], columns=['Turbine'])\n",
        "  setpoint = setpoint.stack().swaplevel(i='Turbine', j='Timestamp')\n",
        "\n",
        "\n",
        "  names = SCADA_setpoint[\"Turbine\"].unique()\n",
        "  names = np.sort(names)\n",
        "  curtailment_widows=[]\n",
        "  turbine_with_curtailments=[]\n",
        "\n",
        "  progresscnt = 0\n",
        "  progressbar = display(progress(0, len(names)), display_id=True)\n",
        "\n",
        "  for name in names:\n",
        "\n",
        "    progresscnt += 1\n",
        "\n",
        "    turbine_data = setpoint.xs(name, level='Turbine').copy()\n",
        "\n",
        "    previous_val = turbine_data['Value'].shift()\n",
        "    current_val = turbine_data['Value']\n",
        "\n",
        "    # isChanged is true when the current value is outside a (user-specified) range \n",
        "    # around the previous value. It is also true if a value close to 0|1\n",
        "    # goes to 0|1 and if a low value comes right after a 0|1 \n",
        "    # (unless count_zero_as_curtailment is set)\n",
        "    turbine_data['isChanged'] = \\\n",
        "      ~within_margin(previous_val, current_val, max_val, difference_ratio=difference_ratio) | \\\n",
        "      ((current_val == max_val) & (previous_val != max_val)) | \\\n",
        "      ((current_val != max_val) & (previous_val == max_val)) | \\\n",
        "      ((((current_val-2 < 0) & (previous_val -2 >= 0)) | \\\n",
        "      ((previous_val-2 < 0) & (current_val -2 >= 0))) & ~count_zero_as_curtailment)\n",
        "\n",
        "    # isCurtailed is True whenever a turbine's setpoint is not at rated power and\n",
        "    # not at 0 or 1 (unless count_zero_as_curtailment is set)\n",
        "    turbine_data['isCurtailed'] = (turbine_data['Value'] != max_val) & \\\n",
        "      (((turbine_data['Value'] != 0)  & (turbine_data['Value']  != 1)) \\\n",
        "      | count_zero_as_curtailment)\n",
        "\n",
        "    # StartCurtailment is whenever the setpoint changes and \n",
        "    #the turbine is curtailed\n",
        "    turbine_data['StartCurtailment'] = turbine_data['isCurtailed'] & \\\n",
        "      turbine_data['isChanged']\n",
        "\n",
        "    # A curtailment window ends when the next value is different and the current\n",
        "    # value is not curtailed. If the data ends with curtailment, an End is added \n",
        "    # too\n",
        "    turbine_data['EndCurtailment'] = \\\n",
        "      turbine_data['isCurtailed'] & turbine_data['isChanged'].shift(-1) | \\\n",
        "      turbine_data['isCurtailed'] & turbine_data['isChanged'].shift(-1).isna()\n",
        "\n",
        "    turbine_curtailments = pd.DataFrame()\n",
        "    # Get first timestamp of active curtailment event\n",
        "    turbine_curtailments['Start'] = turbine_data[turbine_data['StartCurtailment']==True].index\n",
        "\n",
        "    # Get last timestamp of active curtailment event\n",
        "    turbine_curtailments['End'] = turbine_data[turbine_data['EndCurtailment']==True].index\n",
        "\n",
        "    turbine_curtailments = turbine_curtailments.set_index(['Start'])\n",
        "\n",
        "    if additional_flags:\n",
        "      # Add HWRT to turbine data\n",
        "      turbine_data = high_wind_ride_through(turbine_data, \\\n",
        "        SCADA_wind[SCADA_wind['Turbine'] == name])\n",
        "      \n",
        "      # Add HWRT to curtailment windows, if the start of the curtailment has \n",
        "      # high wind (possibly problematic)\n",
        "      turbine_curtailments['HWRT'] = \\\n",
        "        turbine_data.loc[turbine_curtailments.index]['HWRT'].values\n",
        "\n",
        "      # Add technician curtailment flags to turbine data and curtailment data\n",
        "      turbine_data = technician_curtailment(turbine_data)\n",
        "\n",
        "      # A curtailment window is flagged as technician curtailment if the first\n",
        "      # instance of curtailment within its respective turbine's time series data \n",
        "      # is flagged as technician curtailment (possibly problematic)\n",
        "      turbine_curtailments['isTechnicianCurtailment'] = \\\n",
        "      turbine_data.loc[turbine_curtailments.index]['isTechnicianCurtailment']\n",
        "\n",
        "      # Add a flag for reported curtailment\n",
        "      efficient_curtailment_overlap_calculation(turbine_data, curtailment_reports, timeseries=True)\n",
        "      efficient_curtailment_overlap_calculation(turbine_curtailments, curtailment_reports, timeseries=False)\n",
        "\n",
        "      # Expand columns (preparation for next step)\n",
        "      turbine_curtailments = expand_dummy_event_columns(turbine_curtailments, turbine_events)\n",
        "\n",
        "      # Expand turbine curtailment to include event information\n",
        "      single_turbine_events = turbine_events[turbine_events.Turbine == name].sort_values(by=['From'])\n",
        "      single_turbine_events = single_turbine_events.set_index('From')\n",
        "      efficient_event_overlap_calculation(turbine_curtailments, single_turbine_events)\n",
        "\n",
        "    # Add turbine curtailments to the list of curtailment windows per turbine\n",
        "    # The turbines in the list are sorted lexicographically, so GDT001 is the\n",
        "    # first\n",
        "    curtailment_widows.append(turbine_curtailments)\n",
        "    turbine_with_curtailments.append(turbine_data)\n",
        "\n",
        "    # update progress bar\n",
        "    progressbar.update(progress(progresscnt, len(names)))\n",
        "  return curtailment_widows, turbine_with_curtailments\n",
        "\n"
      ],
      "id": "SoZgRiq336-v",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a0iX4ccl6MH"
      },
      "source": [
        "efficient_ovelap_calculation inspired by bechmarking answers in [this stackoverflow post](https://https://stackoverflow.com/questions/50031780/efficiently-find-overlap-of-date-time-ranges-from-2-dataframes)\n",
        "\n"
      ],
      "id": "3a0iX4ccl6MH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPV4WeKE8wXJ"
      },
      "source": [
        "It has been brought to my attention that the analytics package has a events to time series function. Unfortunately, there events are merged, which might lead to major discrepancies between expected results of the statistics part. Additionally, overlap metrics are harder to compute with a time series as opposed to a dataframe with start and end times."
      ],
      "id": "xPV4WeKE8wXJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stp-XhBJFuHZ"
      },
      "source": [
        "Determining **event overlap** with curtailment is a tricky task. There are several challenges:\n",
        "\n",
        "\n",
        "1.   What metric to use? Boolean overlap is easier to compute with respect to both code complexity and runtime efficiency, as it can make use of optimized library methods such as Interval.overlaps, but it also discards a lot of information. Knowing **how much of an event's duration is covered** by curtailment is key to determine its impact and possibly establish causality.\n",
        "2.  The efficient overlap calculation running in O(n) time, where n is the size of the event DataFrame **assumes non-overlapping events**. This assumption holds true for curtailment, but not for the TurbineEvents. looping over the whole event DataFrame in O(n) complexity is a **very slow** operation in native python, so several improvements can be considered.\n",
        "\n",
        "  *   **Pre-filtering** events that are likely to be unrelated. Chief among them are events that exceed the duration of the longest curtailment. This can be tricky, however, as the length of a curtailment event as discovered by this code package is dependent on an arbitrary definition. It could thus be, that what is counted as several chained curtailment events might, in fact, be a single one with variable setpoint. This is a potential **loss of information**.\n",
        "  *   Existing algorithms like [Bentley–Ottmann](https://https://en.wikipedia.org/wiki/Bentley%E2%80%93Ottmann_algorithm) and [sweep line](https://https://en.wikipedia.org/wiki/Sweep_line_algorithm) tackle similar problems but would suffer from **single-threaded execution** due to native python implementations.\n",
        "  * The analytics team has further provided functions that tackle similar problems. Albeit not being applicable to this use case as-is, the remove_overlap function of the lost production factor package hinted at a further option for improvement: the events DataFrame could be restructured into a DataFrame containing **non-overlapping bins of events**. This would enable the use of the efficient **two-pointer algorithm** implementation used previously for comparing detected and reported curtailments; the overlapping bins would be quickly found and overlap would then be exhaustively computed solely for the subset of events in the bins. This approach was however thwarted by the structure of the data: some events can have very long durations, resulting in few bins per turbine. Making this approach efficient leads again to the **information loss - efficiency gain trade-off** mentioned together with pre-filtering.\n",
        "\n",
        "  *   Pandas is mostly built on top of **numpy**, using the very efficient **ndarrays**. Numpy has several advantages compared to native python: [it consists optimized, **pre-compiled C code**](https://https://numpy.org/doc/stable/user/whatisnumpy.html#why-is-numpy-fast), [bypasses the single thread execution dictated by pythons GIL for many array operations](https://https://scipy-cookbook.readthedocs.io/items/ParallelProgramming.html), and thus provides support for efficient **vectorized operations**. This extends to many DataFrame operations as well. A even more efficient backend is provided by the **[eval](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.eval.html#pandas.eval)** of pandas, significantly speeding up comparison queries, which are widely used in overlap calculations. Cython and [numexpr](https://https://github.com/pydata/numexpr) can provide further efficiency gains.\n",
        "\n",
        "3. Unfortunately there are also concerns over **data consistency** to deal with. Chief among them is the often large swaths of **missing time-stamps for the setpoint signal**. During the exploratory phase conducted on data from GDT ranging between January and May 2021, over a sixth of the data is missing for some turbines. **Events are still recorded** for these timestamps, thus contributing to **model bias** in the statistical evaluation part, depending on how the missing setpoint values are handled. On Turbine 58, for instance, 17% of setpoint data is missing, coincidentally when the longest periods of event code 5112 are recorded, which is known to relate to curtailment.\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "stp-XhBJFuHZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ1cYQypOfW1"
      },
      "source": [
        "#### Performance testing (only used in development, before transferring functions in their correct place)"
      ],
      "id": "AJ1cYQypOfW1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IsleGPZuqndf",
        "outputId": "f4f9ee5b-616f-4860-cdb5-8ed29880b7f8"
      },
      "source": [
        "\n",
        "names = SCADA_setpoint[\"Turbine\"].unique()\n",
        "names = np.sort(names)\n",
        "\n",
        "a, b = extract_curtailment_windows(SCADA_setpoint)\n",
        "\n",
        "t0 = time.time()\n",
        "a = expand_dummy_event_columns(a, turbine_events, missing_as_na=True)\n",
        "t1 = time.time()\n",
        "print(t1-t0)\n",
        "\n"
      ],
      "id": "IsleGPZuqndf",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='80'\n",
              "            max='80',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            80\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.23174738883972168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dBZcrj8Yu-hM",
        "outputId": "09728bff-c08e-4e22-baff-bc45ffef6a97"
      },
      "source": [
        "a, b = extract_curtailment_windows(SCADA_setpoint)\n",
        "i =0\n",
        "single_turbine_events = turbine_events[turbine_events['Turbine']==names[i]].sort_values(by=['From'])\n",
        "single_turbine_events = single_turbine_events.set_index('From')\n",
        "\n",
        "turbine_curtailments = a[0].copy()\n",
        "turbine_curtailments = expand_dummy_event_columns(turbine_curtailments, turbine_events)\n",
        "t0 = time.time()\n",
        "efficient_event_overlap_calculation(turbine_curtailments, single_turbine_events)\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "print(t1-t0)"
      ],
      "id": "dBZcrj8Yu-hM",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='80'\n",
              "            max='80',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            80\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.5625910758972168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TOHHRsut7sU8",
        "outputId": "3cf26b41-de6a-4327-da8a-2b20ae7c51f5"
      },
      "source": [
        "t0 = time.time()\n",
        "\n",
        "a, b = extract_curtailment_windows(SCADA_setpoint, additional_flags=True, SCADA_wind=SCADA_wind, curtailment_reports=curtailment_reports, turbine_events=turbine_events)\n",
        "\n",
        "t1 = time.time()\n",
        "print(t1-t0)"
      ],
      "id": "TOHHRsut7sU8",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='80'\n",
              "            max='80',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            80\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "293.547785282135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAQh8En5R9BS",
        "outputId": "1b536e9d-39b4-4aea-9b0b-0e5074909258"
      },
      "source": [
        "print((t1-t0)/60, ' minutes for entire park operation')"
      ],
      "id": "pAQh8En5R9BS",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.8924630880355835  minutes for entire park operation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-1Xld8D6rno1",
        "outputId": "e95017cc-122a-4260-e550-16e72f6df9bd"
      },
      "source": [
        "a, b = extract_curtailment_windows(SCADA_setpoint)\n",
        "\n",
        "names = SCADA_setpoint[\"Turbine\"].unique()\n",
        "names = np.sort(names)\n",
        "\n",
        "turbine_data = b[0]\n",
        "turbine_curtailments = a[0]\n",
        "\n",
        "\n",
        "speedtest = 'eval'\n",
        "\n",
        "\n",
        "\n",
        "if speedtest == 'curtailment_overlap':\n",
        "  reported_curtailments = curtailment_reports.set_index('From')\n",
        "  reported_curtailments = reported_curtailments.sort_index()  \n",
        "  times1 = []\n",
        "  times2 = []\n",
        "  def inefficient_overlap_calculation(df1, df2):\n",
        "    df1['Reported'] = False\n",
        "    for i in range(len(df1)):\n",
        "      for j in range(len(df2)):\n",
        "        r1 = pd.Interval(left=df1.iloc[i].name, right=df1.iloc[i].End)\n",
        "        r2 = pd.Interval(left=df2.iloc[j].name, right=df2.iloc[j].To)\n",
        "        if r1.overlaps(r2):\n",
        "          df1.iat[i, 1] = True\n",
        "\n",
        "  for i in range(10):\n",
        "    print(i)\n",
        "    turbine_data = b[i]\n",
        "    turbine_curtailments = a[i]\n",
        "    t0 = time.time()\n",
        "    inefficient_overlap_calculation(turbine_curtailments, reported_curtailments)\n",
        "    t1 = time.time()\n",
        "    times1.append(t1-t0)\n",
        "\n",
        "  print('slightly optimized old overlap approach: ', np.mean(times1))\n",
        "\n",
        "  for i in range(10):\n",
        "    print(i)\n",
        "    turbine_data = b[i]\n",
        "    turbine_curtailments = a[i]\n",
        "    t0 = time.time()\n",
        "    efficient_curtailment_overlap_calculation(turbine_curtailments, reported_curtailments)\n",
        "    t1 = time.time()\n",
        "    times2.append(t1-t0)\n",
        "\n",
        "  print('optimized new overlap approach: ', np.mean(times2))\n",
        "\n",
        "elif speedtest == 'eval':\n",
        "  \n",
        "  times1 = []\n",
        "  times2 = []\n",
        "\n",
        "  for i in range(10):\n",
        "\n",
        "    print(i)\n",
        "    single_turbine_events = turbine_events[turbine_events['Turbine']==names[i]].sort_values(by=['From'])\n",
        "    single_turbine_events = single_turbine_events.set_index('From')\n",
        "\n",
        "    turbine_curtailments = a[i]\n",
        "\n",
        "    t0 = time.time()\n",
        "    overlappers = [single_turbine_events[(~(single_turbine_events.index > detected_turbine_curtailment.End) & ~(single_turbine_events.To < detected_turbine_curtailment.name))] for detected_turbine_curtailment in turbine_curtailments.iloc]\n",
        "    t1 = time.time()\n",
        "\n",
        "    times2.append(t1-t0)\n",
        "\n",
        "  print('event operation for one turbine without eval: ', np.mean(times2))\n",
        "\n",
        "  for i in range(10):\n",
        "    print(i)\n",
        "\n",
        "    single_turbine_events = turbine_events[turbine_events['Turbine']==names[i]].sort_values(by=['From'])\n",
        "    single_turbine_events = single_turbine_events.set_index('From')\n",
        "\n",
        "    turbine_curtailments = a[i]\n",
        "\n",
        "    t0 = time.time()\n",
        "    overlappers = [single_turbine_events[pd.eval(\"(~(single_turbine_events.index > detected_turbine_curtailment.End) & ~(single_turbine_events.To < detected_turbine_curtailment.name))\", target=single_turbine_events, engine='numexpr')] for detected_turbine_curtailment in turbine_curtailments.iloc]\n",
        "    t1 = time.time()\n",
        "\n",
        "    times1.append(t1-t0)\n",
        "\n",
        "  print('event operation for one turbine with eval: ', np.mean(times1))\n",
        "\n",
        "\n",
        "\n",
        "elif speedtest == 'event_overlap':\n",
        "  times1 = []\n",
        "  times2 = []\n",
        "  def inefficient_overlap_calculation(df1, df2):\n",
        "    df1['Reported'] = False\n",
        "    for i in range(len(df1)):\n",
        "      for j in range(len(df2)):\n",
        "        r1 = pd.Interval(left=df1.iloc[i].name, right=df1.iloc[i].End)\n",
        "        r2 = pd.Interval(left=df2.iloc[j].name, right=df2.iloc[j].To)\n",
        "        if r1.overlaps(r2):\n",
        "          df1.iat[i, 1] = True\n",
        "\n",
        "  for i in range(10):\n",
        "    print(i)\n",
        "    turbine_data = b[i]\n",
        "    turbine_curtailments = a[i]\n",
        "    t0 = time.time()\n",
        "    inefficient_overlap_calculation(turbine_curtailments, reported_curtailments)\n",
        "    t1 = time.time()\n",
        "    times1.append(t1-t0)\n",
        "\n",
        "  print('slightly optimized old overlap approach: ', np.mean(times1))\n",
        "\n",
        "  for i in range(10):\n",
        "    print(i)\n",
        "    turbine_data = b[i]\n",
        "    turbine_curtailments = a[i]\n",
        "    t0 = time.time()\n",
        "    efficient_curtailment_overlap_calculation(turbine_curtailments, reported_curtailments)\n",
        "    t1 = time.time()\n",
        "    times2.append(t1-t0)\n",
        "\n",
        "  print('optimized new overlap approach: ', np.mean(times2))\n",
        "\n",
        "else:\n",
        "  t0 = time.time()\n",
        "  a, b = extract_curtailment_windows(SCADA_setpoint, additional_flags=True, SCADA_wind=SCADA_wind, curtailment_reports=curtailment_reports)\n",
        "  t1 = time.time()\n",
        "  print('full operation for turbine data: ', t1-t0)"
      ],
      "id": "-1Xld8D6rno1",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='80'\n",
              "            max='80',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            80\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "event operation for one turbine without eval:  0.25145878791809084\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "event operation for one turbine with eval:  0.6382174015045166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEriAiXjpga7"
      },
      "source": [
        "Timing curtailment window extraction for **single turbine** resulted in **34 miliseconds** execution time.\n",
        "\n",
        "For all **80 turbines**, the operation took **2.73 seconds**.\n",
        "\n",
        "**High wind ride through** now takes **97 miliseconds per turbine**.\n",
        "\n",
        "Curtailment window extraction with HWRT takes 10.3 seconds for all turbines.\n",
        "\n",
        "**Technician curtailment** estimation was timed at **44 ms**.\n",
        "\n",
        "Curtailment window extraction with all extra features takes **11.0 seconds for all turbines**\n",
        "\n",
        "Performance of basic **reported curtailment flagging** fell from **6.06 seconds** for a short adapted version (simplified and added pandas Interval.overlaps() instead of custom overlap function) of the previous codebase's method to **36 miliseconds** for a new adapted version. This exceeds **150 foldspeedup**. The metrics apply for single turbine data.\n",
        "\n",
        "The old version had a runtime complexity of **O(n*m)** whereas the new one should be **O(max(n,m))**, as it iterates over each dataframe only once. It however **assumes no internal overlap** within each dataframe. \n",
        "An [Interval tree](https://en.wikipedia.org/wiki/Interval_tree) could be considered in this case.\n",
        "\n",
        "Interestingly enough, using numexpr and pandas eval() did not increase performance. On the contrary: it is about **three times slower**; perhaps this could be attributed to higher overhead.\n",
        "\n",
        "**Event overlap** calculation now takes **0.6 seconds** per turbine including expanding the dataframe to several columns\n",
        "\n",
        "The single turbine speed measurements are averages over several turbines.\n",
        "\n",
        "Computing **all turbine-related information** for the entire park takes **5.041 minutes**."
      ],
      "id": "lEriAiXjpga7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjg6RGpOZ11l"
      },
      "source": [
        "### Turbine curtailment statistics"
      ],
      "id": "Qjg6RGpOZ11l"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzwXFtaMySyX"
      },
      "source": [
        "#### Curtailment validation"
      ],
      "id": "AzwXFtaMySyX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M5ZnEByIhnH"
      },
      "source": [
        "def print_validation_statistics_for_curtailment(mydataset: pd.DataFrame, validator: pd.DataFrame) :\n",
        "  \"\"\"\n",
        "  Evaluates precision and recall comparing existing analytics curtailment model\n",
        "  outcomes to this model.\n",
        "\n",
        "  Args:\n",
        "      mydataset: DataFrame containing flagged timeseries\n",
        "      validator: DataFrame used for validating results\n",
        "\n",
        "  Returns:\n",
        "      pretty-printable DataFrames\n",
        "  \"\"\"\n",
        "\n",
        "  # Trim dates\n",
        "  validator = validator[validator.index >= mydataset.index.min()].copy()\n",
        "  validator = validator[validator.index <= mydataset.index.max()]\n",
        "\n",
        "  # Add boolean columns on the validator dataset to facilitate FP and FN calculation\n",
        "  validator['isCurtailed'] = (validator.label == 'reported curtailment') | (validator.label == 'unreported curtailment')\n",
        "\n",
        "  validator['isReported'] = (validator.label == 'reported curtailment')\n",
        "\n",
        "  validator = validator[['isCurtailed', 'isReported']]\n",
        "\n",
        "  # Print length statistics\n",
        "  print(\"length of validation dataset: \", len(validator), \" start date: \", validator.index.min(), \" end date: \", validator.index.max())\n",
        "  print(\"length of dataset to validate: \", len(mydataset), \" start date: \", mydataset.index.min(), \" end date: \", mydataset.index.max())\n",
        "  mergedindex = validator.index.intersection(mydataset.index)\n",
        "  print(\"length of intersected index: \", len(mergedindex), \" start date: \", mergedindex.min(), \" end date: \", mergedindex.max())\n",
        "\n",
        "  validator = validator[validator.index.isin(mergedindex)]\n",
        "  mydataset = mydataset[mydataset.index.isin(mergedindex)]\n",
        "\n",
        "  TP_overall = validator[(validator.isCurtailed == True) & (mydataset.isCurtailed == True)] \n",
        "  TN_overall = mydataset[(validator.isCurtailed == False) & (mydataset.isCurtailed == False)]\n",
        "  FP_overall = mydataset[(validator.isCurtailed == True) & (mydataset.isCurtailed == False)]\n",
        "  FN_overall = mydataset[(validator.isCurtailed == False) & (mydataset.isCurtailed == True)]\n",
        "  total_overall = len(TP_overall)+len(TN_overall)+len(FP_overall)+len(FN_overall)\n",
        "  TPR_overall = len(TP_overall)/(len(TP_overall)+len(FN_overall))\n",
        "  TNR_overall = len(TN_overall)/(len(TN_overall)+len(FP_overall))\n",
        "  accuracy_overall = (len(TP_overall)+len(TN_overall))/(total_overall)\n",
        "  balanced_accuracy_overall = (TPR_overall+TNR_overall)/2\n",
        "  precision_overall = len(TP_overall)/(len(TP_overall)+len(FP_overall))\n",
        "\n",
        "  print(\"\\ngeneral curtailment statistics: \")\n",
        "  print(\"TP: \", len(TP_overall ))\n",
        "  print(\"TN: \", len(TN_overall))\n",
        "  print(\"FP: \", len(FP_overall))\n",
        "  print(\"FN: \", len(FN_overall))\n",
        "  print(\"precision: \", precision_overall, \n",
        "        \" recall/sensitivity/true positive rate: \", TPR_overall, \n",
        "        \" specificity/true negative rate \", TNR_overall)\n",
        "  print(\"accuracy: \", accuracy_overall, \" balanced accuracy: \", balanced_accuracy_overall)\n",
        "\n",
        "  TP_reported = mydataset[(validator.isReported == True) &\n",
        "                          (validator.isCurtailed == True) &\n",
        "                          (mydataset.Reported == True) &\n",
        "                          (mydataset.isCurtailed == True)] \n",
        "  TN_reported = mydataset[(validator.isReported == False) & \n",
        "                          (validator.isCurtailed == False) &\n",
        "                          (mydataset.Reported == False) &                        \n",
        "                          (mydataset.isCurtailed == False)]\n",
        "  FP_reported = mydataset[(validator.isReported == False) &                        \n",
        "                          (validator.isCurtailed == False) &\n",
        "                          (mydataset.Reported == True) &                        \n",
        "                          (mydataset.isCurtailed == True)]\n",
        "  FN_reported = mydataset[(validator.isReported == True) &                        \n",
        "                          (validator.isCurtailed == True) & \n",
        "                          (mydataset.Reported == False) &                        \n",
        "                          (mydataset.isCurtailed == False)]\n",
        "  total_reported = len(TP_reported)+len(TN_reported)+len(FP_reported)+len(FN_reported)\n",
        "  TPR_reported = len(TP_reported)/(len(TP_reported)+len(FN_reported))\n",
        "  TNR_reported = len(TN_reported)/(len(TN_reported)+len(FP_reported))\n",
        "  accuracy_reported = (len(TP_reported)+len(TN_reported))/(total_reported)\n",
        "  balanced_accuracy_reported = (TPR_reported+TNR_reported)/2\n",
        "  precision_reported = len(TP_reported)/(len(TP_reported)+len(FP_reported))\n",
        "\n",
        "  print(\"\\nreported curtailment statistics: \")\n",
        "  print(\"TP: \", len(TP_reported ))\n",
        "  print(\"TN: \", len(TN_reported))\n",
        "  print(\"FP: \", len(FP_reported))\n",
        "  print(\"FN: \", len(FN_reported))\n",
        "  print(\"precision: \", precision_reported, \n",
        "        \" recall/sensitivity/true positive rate: \", TPR_reported, \n",
        "        \" specificity/true negative rate \", TNR_reported)\n",
        "  print(\"accuracy: \", accuracy_reported, \" balanced accuracy: \", balanced_accuracy_reported)\n",
        "\n",
        "  TP_unreported = mydataset[(validator.isCurtailed == True) &\n",
        "                            (validator.isReported == False) & \n",
        "                            (mydataset.isCurtailed== True) &\n",
        "                            (mydataset.Reported == False)] \n",
        "  TN_unreported = mydataset[(validator.isCurtailed == False) &\n",
        "                            (validator.isReported == False) & \n",
        "                            (mydataset.isCurtailed== False) &\n",
        "                            (mydataset.Reported == False)] \n",
        "  FP_unreported = mydataset[(validator.isCurtailed == False) &\n",
        "                            (validator.isReported == False) & \n",
        "                            (mydataset.isCurtailed== True) &\n",
        "                            (mydataset.Reported == False)] \n",
        "  FN_unreported = mydataset[(validator.isCurtailed == True) &\n",
        "                            (validator.isReported == False) & \n",
        "                            (mydataset.isCurtailed== False) &\n",
        "                            (mydataset.Reported == False)] \n",
        "  total_unreported = len(TP_unreported)+len(TN_unreported)+len(FP_unreported)+len(FN_unreported)\n",
        "  try:\n",
        "    TPR_unreported = len(TP_unreported)/(len(TP_unreported)+len(FN_unreported))\n",
        "  except:\n",
        "    TPR_unreported = np.nan\n",
        "  try:\n",
        "    TNR_unreported = len(TN_unreported)/(len(TN_unreported)+len(FP_unreported))\n",
        "  except:\n",
        "    TNR_unreported = np.nan\n",
        "  accuracy_unreported = (len(TP_unreported)+len(TN_unreported))/(total_unreported)\n",
        "  balanced_accuracy_unreported = (TPR_unreported+TNR_unreported)/2\n",
        "  precision_unreported = len(TP_unreported)/(len(TP_unreported)+len(FP_unreported))\n",
        "\n",
        "  print(\"\\nunreported curtailment statistics: \")\n",
        "  print(\"TP: \", len(TP_unreported ))\n",
        "  print(\"TN: \", len(TN_unreported))\n",
        "  print(\"FP: \", len(FP_unreported))\n",
        "  print(\"FN: \", len(FN_unreported))\n",
        "  print(\"precision: \", precision_unreported, \n",
        "        \" recall/sensitivity/true positive rate: \", TPR_unreported, \n",
        "        \" specificity/true negative rate \", TNR_unreported)\n",
        "  print(\"accuracy: \", accuracy_unreported, \" balanced accuracy: \", balanced_accuracy_unreported)\n",
        "\n",
        "  output_overall = pd.DataFrame()\n",
        "  output_overall['TP'] = [len(TP_overall)]\n",
        "  output_overall['TN'] = len(TN_overall)\n",
        "  output_overall['FP'] = len(FP_overall)\n",
        "  output_overall['FN'] = len(FN_overall)\n",
        "  output_overall['TPR'] = TPR_overall\n",
        "  output_overall['TNR'] = TNR_overall\n",
        "  output_overall['precision'] = precision_overall\n",
        "  output_overall['accuracy'] = accuracy_overall\n",
        "  output_overall['balanced accuracy'] = balanced_accuracy_overall\n",
        "\n",
        "  output_reported = pd.DataFrame()\n",
        "  output_reported['TP'] = [len(TP_reported)]\n",
        "  output_reported['TN'] = len(TN_reported)\n",
        "  output_reported['FP'] = len(FP_reported)\n",
        "  output_reported['FN'] = len(FN_reported)\n",
        "  output_reported['TPR'] = TPR_reported\n",
        "  output_reported['TNR'] = TNR_reported\n",
        "  output_reported['precision'] = precision_reported\n",
        "  output_reported['accuracy'] = accuracy_reported\n",
        "  output_reported['balanced accuracy'] = balanced_accuracy_reported\n",
        "\n",
        "  output_unreported = pd.DataFrame()\n",
        "  output_unreported['TP'] = [len(TP_unreported)]\n",
        "  output_unreported['TN'] = len(TN_unreported)\n",
        "  output_unreported['FP'] = len(FP_unreported)\n",
        "  output_unreported['FN'] = len(FN_unreported)\n",
        "  output_unreported['TPR'] = TPR_unreported\n",
        "  output_unreported['TNR'] = TNR_unreported\n",
        "  output_unreported['precision'] = precision_unreported\n",
        "  output_unreported['accuracy'] = accuracy_unreported\n",
        "  output_unreported['balanced accuracy'] = balanced_accuracy_unreported\n",
        "\n",
        "\n",
        "  return output_overall, output_reported, output_unreported"
      ],
      "id": "7M5ZnEByIhnH",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "T-xsOGprysAX",
        "outputId": "5a54d312-b212-47d8-b883-5321fb49ef22"
      },
      "source": [
        "a1, setpoint_curtailment_timeseries_with_zeroes_filled = extract_curtailment_windows(SCADA_setpoint, \n",
        "                                                                                    fill_missing_data=True, \n",
        "                                                                                    count_zero_as_curtailment=True, \n",
        "                                                                                    additional_flags=True, \n",
        "                                                                                    curtailment_reports=curtailment_reports, \n",
        "                                                                                    turbine_events=turbine_events, \n",
        "                                                                                    SCADA_wind=SCADA_wind)\n",
        "a2, setpoint_curtailment_timeseries_with_zeroes_unfilled = extract_curtailment_windows(SCADA_setpoint, \n",
        "                                                                                    fill_missing_data=False, \n",
        "                                                                                    count_zero_as_curtailment=True, \n",
        "                                                                                    additional_flags=True, \n",
        "                                                                                    curtailment_reports=curtailment_reports, \n",
        "                                                                                    turbine_events=turbine_events, \n",
        "                                                                                    SCADA_wind=SCADA_wind)\n",
        "a3, setpoint_curtailment_timeseries_without_zeroes_unfilled = extract_curtailment_windows(SCADA_setpoint, \n",
        "                                                                                    fill_missing_data=False, \n",
        "                                                                                    count_zero_as_curtailment=False, \n",
        "                                                                                    additional_flags=True, \n",
        "                                                                                    curtailment_reports=curtailment_reports, \n",
        "                                                                                    turbine_events=turbine_events, \n",
        "                                                                                    SCADA_wind=SCADA_wind)"
      ],
      "id": "T-xsOGprysAX",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='80'\n",
              "            max='80',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            80\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='80'\n",
              "            max='80',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            80\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='80'\n",
              "            max='80',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            80\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaBOYtg0zcDx",
        "outputId": "e12d076c-2399-4273-fd45-1834a2c9267e"
      },
      "source": [
        "print(\"Data according to current analytics methods:\")\n",
        "print(\"First timestamp: \", Val_GDT004.iloc[0].name, \" and last: \", Val_GDT004.iloc[len(Val_GDT004)-1].name)\n",
        "print('length GDT004: ', len(Val_GDT004))\n",
        "print('Reported curtailment instances in GDT004: ', len(Val_GDT004[Val_GDT004.label == 'reported curtailment']), \" in percent: \", len(Val_GDT004[Val_GDT004.label == 'reported curtailment'])/len(Val_GDT004)*100, \"%\")\n",
        "print('Unreported curtailment instances in GDT004: ', len(Val_GDT004[Val_GDT004.label == 'unreported curtailment']), \" in percent: \", len(Val_GDT004[Val_GDT004.label == 'unreported curtailment'])/len(Val_GDT004)*100, \"%\")\n",
        "print('Alarm instances in GDT004: ', len(Val_GDT004[Val_GDT004.label == 'alarm']), \" in percent: \", len(Val_GDT004[Val_GDT004.label == 'alarm'])/len(Val_GDT004)*100, \"%\")\n",
        "print('Outlier instances in GDT004: ', len(Val_GDT004[Val_GDT004.label == 'outlier']), \" in percent: \", len(Val_GDT004[Val_GDT004.label == 'outlier'])/len(Val_GDT004)*100, \"%\")"
      ],
      "id": "XaBOYtg0zcDx",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data according to current analytics methods:\n",
            "First timestamp:  2020-01-01 00:00:00  and last:  2021-05-31 23:40:00\n",
            "length GDT004:  41335\n",
            "Reported curtailment instances in GDT004:  4797  in percent:  11.605177210596347 %\n",
            "Unreported curtailment instances in GDT004:  49  in percent:  0.11854360711261643 %\n",
            "Alarm instances in GDT004:  133  in percent:  0.32176121930567314 %\n",
            "Outlier instances in GDT004:  195  in percent:  0.47175517116245314 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3ELeucEGcvu",
        "outputId": "47ed2beb-c7be-46b0-d9b0-2c23f010a856"
      },
      "source": [
        "print(\"Data according to this model with zero production counting as curtailment and missing timestamps filled:\")\n",
        "print(\"First timestamp: \", setpoint_curtailment_timeseries_with_zeroes_filled[3].iloc[0].name, \" and last: \", setpoint_curtailment_timeseries_with_zeroes_filled[3].iloc[len(setpoint_curtailment_timeseries_with_zeroes_filled[3])-1].name)\n",
        "print('length GDT004: ', len(setpoint_curtailment_timeseries_with_zeroes_filled[3]))\n",
        "print('Reported curtailment instances in GDT004: ', len(setpoint_curtailment_timeseries_with_zeroes_filled[3][setpoint_curtailment_timeseries_with_zeroes_filled[3].Reported == True]), \" in percent: \", len(setpoint_curtailment_timeseries_with_zeroes_filled[3][setpoint_curtailment_timeseries_with_zeroes_filled[3].Reported == True])/len(setpoint_curtailment_timeseries_with_zeroes_filled[3])*100, \"%\")\n",
        "print('Unreported curtailment instances in GDT004: ', len(setpoint_curtailment_timeseries_with_zeroes_filled[3][(setpoint_curtailment_timeseries_with_zeroes_filled[3].Reported == False) & (setpoint_curtailment_timeseries_with_zeroes_filled[3].isCurtailed == True)]), \" in percent: \", len(setpoint_curtailment_timeseries_with_zeroes_filled[3][(setpoint_curtailment_timeseries_with_zeroes_filled[3].Reported == False) & (setpoint_curtailment_timeseries_with_zeroes_filled[3].isCurtailed == True)])/len(setpoint_curtailment_timeseries_with_zeroes_filled[3])*100, \"%\")"
      ],
      "id": "Z3ELeucEGcvu",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data according to this model with zero production counting as curtailment and missing timestamps filled:\n",
            "First timestamp:  2021-01-01 00:10:00  and last:  2021-04-30 23:50:00\n",
            "length GDT004:  17091\n",
            "Reported curtailment instances in GDT004:  2875  in percent:  16.821719033409398 %\n",
            "Unreported curtailment instances in GDT004:  94  in percent:  0.5499970744836464 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okS_jG0UHznD",
        "outputId": "0bc53d4e-10c2-421f-af88-8734f8854c9f"
      },
      "source": [
        "print(\"Data according to this model with zero production not counting as curtailment and missing timestamps left out:\")\n",
        "print(\"First timestamp: \", setpoint_curtailment_timeseries_without_zeroes_unfilled[3].iloc[0].name, \" and last: \", setpoint_curtailment_timeseries_without_zeroes_unfilled[3].iloc[len(setpoint_curtailment_timeseries_without_zeroes_unfilled[3])-1].name)\n",
        "print('length GDT004: ', len(setpoint_curtailment_timeseries_without_zeroes_unfilled[3]))\n",
        "print('Reported curtailment instances in GDT004: ', len(setpoint_curtailment_timeseries_without_zeroes_unfilled[3][setpoint_curtailment_timeseries_without_zeroes_unfilled[3].Reported == True]), \" in percent: \", len(setpoint_curtailment_timeseries_without_zeroes_unfilled[3][setpoint_curtailment_timeseries_without_zeroes_unfilled[3].Reported == True])/len(setpoint_curtailment_timeseries_without_zeroes_unfilled[3])*100, \"%\")\n",
        "print('Unreported curtailment instances in GDT004: ', len(setpoint_curtailment_timeseries_without_zeroes_unfilled[3][(setpoint_curtailment_timeseries_without_zeroes_unfilled[3].Reported == False) & (setpoint_curtailment_timeseries_without_zeroes_unfilled[3].isCurtailed == True)]), \" in percent: \", len(setpoint_curtailment_timeseries_without_zeroes_unfilled[3][(setpoint_curtailment_timeseries_without_zeroes_unfilled[3].Reported == False) & (setpoint_curtailment_timeseries_without_zeroes_unfilled[3].isCurtailed == True)])/len(setpoint_curtailment_timeseries_without_zeroes_unfilled[3])*100, \"%\")"
      ],
      "id": "okS_jG0UHznD",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data according to this model with zero production not counting as curtailment and missing timestamps left out:\n",
            "First timestamp:  2021-01-01 00:10:00  and last:  2021-04-30 23:50:00\n",
            "length GDT004:  17072\n",
            "Reported curtailment instances in GDT004:  2870  in percent:  16.81115276476101 %\n",
            "Unreported curtailment instances in GDT004:  80  in percent:  0.4686035613870665 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLlpmVM-eNJt",
        "outputId": "5497e0d5-f96e-4459-fb36-cc1a40c944f6"
      },
      "source": [
        "print(\"Validation GDT004\")\n",
        "a, b, c = print_validation_statistics_for_curtailment(setpoint_curtailment_timeseries_without_zeroes_unfilled[3], Val_GDT004)"
      ],
      "id": "tLlpmVM-eNJt",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation GDT004\n",
            "length of validation dataset:  8839  start date:  2021-01-01 05:10:00  end date:  2021-04-23 06:10:00\n",
            "length of dataset to validate:  17072  start date:  2021-01-01 00:10:00  end date:  2021-04-30 23:50:00\n",
            "length of intersected index:  8830  start date:  2021-01-01 05:10:00  end date:  2021-04-22 17:40:00\n",
            "\n",
            "general curtailment statistics: \n",
            "TP:  1210\n",
            "TN:  7452\n",
            "FP:  149\n",
            "FN:  19\n",
            "precision:  0.8903605592347315  recall/sensitivity/true positive rate:  0.9845402766476811  specificity/true negative rate  0.9803973161426128\n",
            "accuracy:  0.9809739524348811  balanced accuracy:  0.982468796395147\n",
            "\n",
            "reported curtailment statistics: \n",
            "TP:  1169\n",
            "TN:  7437\n",
            "FP:  0\n",
            "FN:  0\n",
            "precision:  1.0  recall/sensitivity/true positive rate:  1.0  specificity/true negative rate  1.0\n",
            "accuracy:  1.0  balanced accuracy:  1.0\n",
            "\n",
            "unreported curtailment statistics: \n",
            "TP:  41\n",
            "TN:  7437\n",
            "FP:  19\n",
            "FN:  0\n",
            "precision:  0.6833333333333333  recall/sensitivity/true positive rate:  1.0  specificity/true negative rate  0.9974517167381974\n",
            "accuracy:  0.9974656529278378  balanced accuracy:  0.9987258583690988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9XIQHWC3Irb",
        "outputId": "44183254-7364-4707-9187-fdfb437883ae"
      },
      "source": [
        "print(\"Validation GDT005\")\n",
        "a1, b1, c1 = print_validation_statistics_for_curtailment(setpoint_curtailment_timeseries_without_zeroes_unfilled[4], Val_GDT005)\n",
        "a = a.append(a1)\n",
        "b = b.append(b1)\n",
        "c = c.append(c1)"
      ],
      "id": "g9XIQHWC3Irb",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation GDT005\n",
            "length of validation dataset:  8063  start date:  2021-01-01 22:30:00  end date:  2021-04-23 06:10:00\n",
            "length of dataset to validate:  17067  start date:  2021-01-01 00:10:00  end date:  2021-04-30 23:50:00\n",
            "length of intersected index:  8061  start date:  2021-01-01 22:30:00  end date:  2021-04-22 17:40:00\n",
            "\n",
            "general curtailment statistics: \n",
            "TP:  1032\n",
            "TN:  6852\n",
            "FP:  152\n",
            "FN:  25\n",
            "precision:  0.8716216216216216  recall/sensitivity/true positive rate:  0.9763481551561022  specificity/true negative rate  0.9782981153626499\n",
            "accuracy:  0.9780424264979531  balanced accuracy:  0.9773231352593761\n",
            "\n",
            "reported curtailment statistics: \n",
            "TP:  1001\n",
            "TN:  6837\n",
            "FP:  0\n",
            "FN:  0\n",
            "precision:  1.0  recall/sensitivity/true positive rate:  1.0  specificity/true negative rate  1.0\n",
            "accuracy:  1.0  balanced accuracy:  1.0\n",
            "\n",
            "unreported curtailment statistics: \n",
            "TP:  31\n",
            "TN:  6837\n",
            "FP:  25\n",
            "FN:  0\n",
            "precision:  0.5535714285714286  recall/sensitivity/true positive rate:  1.0  specificity/true negative rate  0.996356747303993\n",
            "accuracy:  0.996373132163064  balanced accuracy:  0.9981783736519965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4JmvGd03Orh",
        "outputId": "ab08d5d6-5555-46d0-9c34-c9a62c3660c8"
      },
      "source": [
        "print(\"Validation GDT022\")\n",
        "a1, b1, c1 = print_validation_statistics_for_curtailment(setpoint_curtailment_timeseries_without_zeroes_unfilled[21], Val_GDT022)\n",
        "a = a.append(a1)\n",
        "b = b.append(b1)\n",
        "c = c.append(c1)"
      ],
      "id": "Z4JmvGd03Orh",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation GDT022\n",
            "length of validation dataset:  10401  start date:  2021-01-01 04:30:00  end date:  2021-04-23 05:50:00\n",
            "length of dataset to validate:  17067  start date:  2021-01-01 00:10:00  end date:  2021-04-30 23:50:00\n",
            "length of intersected index:  10389  start date:  2021-01-01 04:30:00  end date:  2021-04-22 17:40:00\n",
            "\n",
            "general curtailment statistics: \n",
            "TP:  1742\n",
            "TN:  6952\n",
            "FP:  333\n",
            "FN:  1362\n",
            "precision:  0.8395180722891566  recall/sensitivity/true positive rate:  0.5612113402061856  specificity/true negative rate  0.954289636238847\n",
            "accuracy:  0.8368466647415536  balanced accuracy:  0.7577504882225163\n",
            "\n",
            "reported curtailment statistics: \n",
            "TP:  1249\n",
            "TN:  6940\n",
            "FP:  4\n",
            "FN:  0\n",
            "precision:  0.9968076616121309  recall/sensitivity/true positive rate:  1.0  specificity/true negative rate  0.9994239631336406\n",
            "accuracy:  0.9995117783473697  balanced accuracy:  0.9997119815668203\n",
            "\n",
            "unreported curtailment statistics: \n",
            "TP:  491\n",
            "TN:  6940\n",
            "FP:  1358\n",
            "FN:  0\n",
            "precision:  0.26554894537587886  recall/sensitivity/true positive rate:  1.0  specificity/true negative rate  0.8363461074957821\n",
            "accuracy:  0.8454886790306064  balanced accuracy:  0.918173053747891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBF3QU4f3XHB",
        "outputId": "de57cc80-1f02-4cd8-c12e-95dcbdb8eaf8"
      },
      "source": [
        "print(\"Validation GDT024\")\n",
        "a1, b1, c1 = print_validation_statistics_for_curtailment(setpoint_curtailment_timeseries_without_zeroes_unfilled[23], Val_GDT024)\n",
        "a = a.append(a1)\n",
        "b = b.append(b1)\n",
        "c = c.append(c1)"
      ],
      "id": "xBF3QU4f3XHB",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation GDT024\n",
            "length of validation dataset:  5055  start date:  2021-01-01 04:30:00  end date:  2021-04-23 05:50:00\n",
            "length of dataset to validate:  17060  start date:  2021-01-01 00:10:00  end date:  2021-04-30 23:50:00\n",
            "length of intersected index:  5043  start date:  2021-01-01 04:30:00  end date:  2021-04-21 21:50:00\n",
            "\n",
            "general curtailment statistics: \n",
            "TP:  259\n",
            "TN:  4411\n",
            "FP:  359\n",
            "FN:  14\n",
            "precision:  0.4190938511326861  recall/sensitivity/true positive rate:  0.9487179487179487  specificity/true negative rate  0.9247379454926625\n",
            "accuracy:  0.9260360896291889  balanced accuracy:  0.9367279471053056\n",
            "\n",
            "reported curtailment statistics: \n",
            "TP:  259\n",
            "TN:  4402\n",
            "FP:  8\n",
            "FN:  0\n",
            "precision:  0.9700374531835206  recall/sensitivity/true positive rate:  1.0  specificity/true negative rate  0.9981859410430839\n",
            "accuracy:  0.9982865710002142  balanced accuracy:  0.9990929705215419\n",
            "\n",
            "unreported curtailment statistics: \n",
            "TP:  0\n",
            "TN:  4402\n",
            "FP:  6\n",
            "FN:  0\n",
            "precision:  0.0  recall/sensitivity/true positive rate:  nan  specificity/true negative rate  0.9986388384754991\n",
            "accuracy:  0.9986388384754991  balanced accuracy:  nan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7dR-oT0hHW_",
        "outputId": "b1e99b17-f336-47b9-d9f0-7fe831bddd37"
      },
      "source": [
        "print(\"Validation GDT025\")\n",
        "a1, b1, c1 = print_validation_statistics_for_curtailment(setpoint_curtailment_timeseries_without_zeroes_unfilled[24], Val_GDT025)\n",
        "a = a.append(a1)\n",
        "b = b.append(b1)\n",
        "c = c.append(c1)"
      ],
      "id": "r7dR-oT0hHW_",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation GDT025\n",
            "length of validation dataset:  4904  start date:  2021-01-01 04:40:00  end date:  2021-04-29 16:40:00\n",
            "length of dataset to validate:  17068  start date:  2021-01-01 00:10:00  end date:  2021-04-30 23:50:00\n",
            "length of intersected index:  4897  start date:  2021-01-01 04:40:00  end date:  2021-04-19 23:50:00\n",
            "\n",
            "general curtailment statistics: \n",
            "TP:  653\n",
            "TN:  4157\n",
            "FP:  78\n",
            "FN:  9\n",
            "precision:  0.893296853625171  recall/sensitivity/true positive rate:  0.986404833836858  specificity/true negative rate  0.981582054309327\n",
            "accuracy:  0.9822340208290791  balanced accuracy:  0.9839934440730924\n",
            "\n",
            "reported curtailment statistics: \n",
            "TP:  652\n",
            "TN:  4149\n",
            "FP:  0\n",
            "FN:  0\n",
            "precision:  1.0  recall/sensitivity/true positive rate:  1.0  specificity/true negative rate  1.0\n",
            "accuracy:  1.0  balanced accuracy:  1.0\n",
            "\n",
            "unreported curtailment statistics: \n",
            "TP:  1\n",
            "TN:  4149\n",
            "FP:  9\n",
            "FN:  0\n",
            "precision:  0.1  recall/sensitivity/true positive rate:  1.0  specificity/true negative rate  0.9978354978354979\n",
            "accuracy:  0.9978360182736234  balanced accuracy:  0.998917748917749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXW-WUrILcbB"
      },
      "source": [
        "Across all three measured properties (curtailment in general and reported vs. unreported curtailment more specifically) we can see that **the model performs very well**. Results are **similar to** those achieved with **the current analytics model** for timestamps both have in common.\n",
        "With **unreported curtailment, very low precision yet high accuracy** rates can be seen.\n",
        "This is arguably due to the new model **finding more instances** of unreported curtailment"
      ],
      "id": "bXW-WUrILcbB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1ZJkadfCxXe"
      },
      "source": [
        "valturbines = ['GDT004','GDT005','GDT022','GDT024','GDT025']\n",
        "a['Turbines'] = valturbines\n",
        "b['Turbines'] = valturbines\n",
        "c['Turbines'] = valturbines"
      ],
      "id": "c1ZJkadfCxXe",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYgFnR308NfW"
      },
      "source": [
        "\n",
        "a.set_index('Turbines', inplace=True, drop=True)\n",
        "b.set_index('Turbines', inplace=True, drop=True)\n",
        "c.set_index('Turbines', inplace=True, drop=True)\n"
      ],
      "id": "HYgFnR308NfW",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "Z6HQ12yO8paG",
        "outputId": "4da31bc4-ef7d-4321-f54e-9472e8e1ad3c"
      },
      "source": [
        "a.to_latex()"
      ],
      "id": "Z6HQ12yO8paG",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\\\begin{tabular}{lrrrrrrrrr}\\n\\\\toprule\\n{} &    TP &    TN &   FP &    FN &       TPR &       TNR &  precision &  accuracy &  balanced accuracy \\\\\\\\\\nTurbines &       &       &      &       &           &           &            &           &                    \\\\\\\\\\n\\\\midrule\\nGDT004   &  1210 &  7452 &  149 &    19 &  0.984540 &  0.980397 &   0.890361 &  0.980974 &           0.982469 \\\\\\\\\\nGDT005   &  1032 &  6852 &  152 &    25 &  0.976348 &  0.978298 &   0.871622 &  0.978042 &           0.977323 \\\\\\\\\\nGDT022   &  1742 &  6952 &  333 &  1362 &  0.561211 &  0.954290 &   0.839518 &  0.836847 &           0.757750 \\\\\\\\\\nGDT024   &   259 &  4411 &  359 &    14 &  0.948718 &  0.924738 &   0.419094 &  0.926036 &           0.936728 \\\\\\\\\\nGDT025   &   653 &  4157 &   78 &     9 &  0.986405 &  0.981582 &   0.893297 &  0.982234 &           0.983993 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "1e4-5Is38pvW",
        "outputId": "45edcf5e-6751-413d-bb11-c1378bca3fab"
      },
      "source": [
        "b.to_latex()"
      ],
      "id": "1e4-5Is38pvW",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\\\begin{tabular}{lrrrrrrrrr}\\n\\\\toprule\\n{} &    TP &    TN &  FP &  FN &  TPR &       TNR &  precision &  accuracy &  balanced accuracy \\\\\\\\\\nTurbines &       &       &     &     &      &           &            &           &                    \\\\\\\\\\n\\\\midrule\\nGDT004   &  1169 &  7437 &   0 &   0 &  1.0 &  1.000000 &   1.000000 &  1.000000 &           1.000000 \\\\\\\\\\nGDT005   &  1001 &  6837 &   0 &   0 &  1.0 &  1.000000 &   1.000000 &  1.000000 &           1.000000 \\\\\\\\\\nGDT022   &  1249 &  6940 &   4 &   0 &  1.0 &  0.999424 &   0.996808 &  0.999512 &           0.999712 \\\\\\\\\\nGDT024   &   259 &  4402 &   8 &   0 &  1.0 &  0.998186 &   0.970037 &  0.998287 &           0.999093 \\\\\\\\\\nGDT025   &   652 &  4149 &   0 &   0 &  1.0 &  1.000000 &   1.000000 &  1.000000 &           1.000000 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "hVj3UHHW8p8-",
        "outputId": "fe7e2d23-c896-45be-e80f-b69ba45196ae"
      },
      "source": [
        "c.to_latex()"
      ],
      "id": "hVj3UHHW8p8-",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\\\begin{tabular}{lrrrrrrrrr}\\n\\\\toprule\\n{} &   TP &    TN &    FP &  FN &  TPR &       TNR &  precision &  accuracy &  balanced accuracy \\\\\\\\\\nTurbines &      &       &       &     &      &           &            &           &                    \\\\\\\\\\n\\\\midrule\\nGDT004   &   41 &  7437 &    19 &   0 &  1.0 &  0.997452 &   0.683333 &  0.997466 &           0.998726 \\\\\\\\\\nGDT005   &   31 &  6837 &    25 &   0 &  1.0 &  0.996357 &   0.553571 &  0.996373 &           0.998178 \\\\\\\\\\nGDT022   &  491 &  6940 &  1358 &   0 &  1.0 &  0.836346 &   0.265549 &  0.845489 &           0.918173 \\\\\\\\\\nGDT024   &    0 &  4402 &     6 &   0 &  NaN &  0.998639 &   0.000000 &  0.998639 &                NaN \\\\\\\\\\nGDT025   &    1 &  4149 &     9 &   0 &  1.0 &  0.997835 &   0.100000 &  0.997836 &           0.998918 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe_0ZJUl_iVP",
        "outputId": "d5f151a0-0226-46c7-ef1f-1b80db47fe8f"
      },
      "source": [
        "len(Val_GDT024[((Val_GDT024.label == 'reported curtailment') | (Val_GDT024.label == 'unreported curtailment')) & (Val_GDT024.index >= '2021-01-01 00:00:00') & (Val_GDT024.index < '2021-05-01 00:00:00')])"
      ],
      "id": "Oe_0ZJUl_iVP",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "618"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKMgnin-GXiS",
        "outputId": "8e978f7c-e199-4064-e043-20e464dda3c9"
      },
      "source": [
        "len(setpoint_curtailment_timeseries_without_zeroes_unfilled[23][setpoint_curtailment_timeseries_without_zeroes_unfilled[23].Reported == True])"
      ],
      "id": "uKMgnin-GXiS",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2870"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMjxb7ruyNBi"
      },
      "source": [
        "#### Event-related"
      ],
      "id": "jMjxb7ruyNBi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "YY0-FXg80JBx",
        "outputId": "78e7450b-fc63-4703-8fa3-bf32c2058d95"
      },
      "source": [
        "a, b = extract_curtailment_windows(SCADA_setpoint, fill_missing_data=True, count_zero_as_curtailment=True)\n",
        "\n",
        "names = SCADA_setpoint[\"Turbine\"].unique()\n",
        "names = np.sort(names)\n",
        "\n",
        "\n",
        "single_turbine_events = turbine_events[turbine_events['Turbine']==names[0]].sort_values(by=['From'])\n",
        "single_turbine_events = single_turbine_events.set_index('From')\n",
        "\n",
        "turbine_curtailments = a[0].copy()\n",
        "turbine_curtailments = expand_dummy_event_columns(turbine_curtailments, turbine_events, missing_as_na=True)\n",
        "\n",
        "#display(single_turbine_events[single_turbine_events.ErrorCode == 5112])\n",
        "#display(SCADA_setpoint[(SCADA_setpoint.Turbine == 'GDT001') & (SCADA_setpoint.Timestamp > '2021-04-22 17:00:00') & (SCADA_setpoint.Timestamp < '2021-04-23 06:50:00')])\n",
        "t0 = time.time()\n",
        "efficient_event_overlap_calculation(turbine_curtailments, single_turbine_events)\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "print(t1-t0)"
      ],
      "id": "YY0-FXg80JBx",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='80'\n",
              "            max='80',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            80\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.5643906593322754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "fxeXfIU0hHPV",
        "outputId": "1e23965a-ffff-4e3f-9366-e85a01c957c1"
      },
      "source": [
        "t0 = time.time()\n",
        "\n",
        "curtailments_without_zeroes, timeseries_without_zeroes = extract_curtailment_windows(SCADA_setpoint, additional_flags=True, fill_missing_data=False, SCADA_wind=SCADA_wind, curtailment_reports=curtailment_reports, turbine_events=turbine_events)\n",
        "\n",
        "t1 = time.time()\n",
        "print(t1-t0)\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "curtailments_with_zeroes, timeseries_with_zeroes = extract_curtailment_windows(SCADA_setpoint, additional_flags=True, fill_missing_data=True, count_zero_as_curtailment=True, SCADA_wind=SCADA_wind, curtailment_reports=curtailment_reports, turbine_events=turbine_events)\n",
        "\n",
        "t1 = time.time()\n",
        "print(t1-t0)"
      ],
      "id": "fxeXfIU0hHPV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='80'\n",
              "            max='80',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            80\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "293.1967988014221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='44'\n",
              "            max='80',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            44\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBsh48hIZ7L3"
      },
      "source": [
        "def compute_duration_coverage(turbine_curtailments: pd.DataFrame, turbine_events: pd.DataFrame, filter_known_curtailment=False, filter_technician=True, compute_difference_5112=False):\n",
        "  \"\"\"\n",
        "  Rank events according to how much of their total duration is covered \n",
        "  by curtailment.\n",
        "\n",
        "  Args:\n",
        "      turbine_curtailments: DataFrame containing flagged curtailment data for\n",
        "      one turbine. All event flags required\n",
        "\n",
        "      turbine_events: raw event DataFrame\n",
        "\n",
        "      filter_known_curtailment: if True, only curtailment with unknown causes\n",
        "      will be used. NB: unknown curtailment triggers might still happen while \n",
        "      a reported curtailment is active or while wind is high.\n",
        "\n",
        "      compute_difference_5112: if True difference between total duration of 5112\n",
        "      events and durations covered by curtailment will be computed. This is \n",
        "      mainly used to check which turbines are more affected by 5112 (for dev\n",
        "      purposes)\n",
        "\n",
        "      filter_technician = include technician curtailment in the filtering process\n",
        "\n",
        "  Returns:\n",
        "      DataFrame with rankeable events (and a debug dataframe containing \n",
        "      information pertaining event 5112)\n",
        "  \"\"\"\n",
        "\n",
        "  codes = turbine_events['ErrorCode'].unique()\n",
        "  codes = np.sort(codes)\n",
        "\n",
        "  turbines = SCADA_setpoint[\"Turbine\"].unique()\n",
        "  turbines = np.sort(names)\n",
        "\n",
        "  discovered_curtailments = turbine_curtailments\n",
        "\n",
        "  covered_ratio_data = pd.DataFrame(data=0, index=codes, columns=['total_covered_duration'])\n",
        "  col_names = [str(code) + '_Coverage_Duration' for code in codes]\n",
        "      \n",
        "  if compute_difference_5112:\n",
        "    difference_ratio = pd.DataFrame(data=0, index=turbines, columns=['covered_dur','total_dur'])\n",
        "\n",
        "  progressbar = display(progress(0, len(discovered_curtailments)), display_id=True)\n",
        "  i = 0\n",
        "  # Iterate over list of turbine curtailments\n",
        "  for curtailment_data in discovered_curtailments:\n",
        "\n",
        "    #Filter data if causes already known and if parameter set\n",
        "    if filter_known_curtailment:\n",
        "      if filter_technician:\n",
        "        tmp = curtailment_data[~curtailment_data.Reported & \n",
        "                              ~curtailment_data.HWRT & \n",
        "                              ~curtailment_data.isTechnicianCurtailment].agg(\n",
        "                                  ['sum'])[col_names]\n",
        "      else:\n",
        "          tmp = curtailment_data[~curtailment_data.Reported & \n",
        "                              ~curtailment_data.HWRT].agg(\n",
        "                                  ['sum'])[col_names]\n",
        "    else:\n",
        "      tmp = curtailment_data.agg(['sum'])[col_names]\n",
        "    \n",
        "    if compute_difference_5112:\n",
        "      #Compute difference \n",
        "      difference_ratio.at[turbines[i], 'covered_dur'] = tmp['5112_Coverage_Duration']\n",
        "      difference_ratio.at[turbines[i], 'total_dur'] = turbine_events[turbine_events.Turbine == turbines[i]].groupby(by=['ErrorCode']).Duration.sum().dt.total_seconds().loc[5112]\n",
        "\n",
        "    tmp.columns = codes\n",
        "    tmp = tmp.transpose()\n",
        "    tmp.columns = ['total_covered_duration']\n",
        "    covered_ratio_data = covered_ratio_data+tmp\n",
        "    i += 1\n",
        "    progressbar.update(progress(i, len(discovered_curtailments)))\n",
        "\n",
        "  if compute_difference_5112:\n",
        "    difference_ratio['difference'] = difference_ratio['total_dur']-difference_ratio['covered_dur']\n",
        "\n",
        "  covered_ratio_data['total_duration'] = turbine_events.groupby(by=['ErrorCode']).Duration.sum().dt.total_seconds()\n",
        "\n",
        "  covered_ratio_data['total_coverage_ratio'] = (covered_ratio_data['total_covered_duration']/covered_ratio_data['total_duration'])\n",
        "  covered_ratio_data['total_coverage_ratio'].fillna(0)\n",
        "\n",
        "  if compute_difference_5112:\n",
        "    return covered_ratio_data, difference_ratio\n",
        "  else:\n",
        "    return covered_ratio_data\n"
      ],
      "id": "WBsh48hIZ7L3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW2rRfplIR3s"
      },
      "source": [
        "with_zeroes = curtailments_with_zeroes.copy()\n",
        "stats_zeroes, covered_ratio_zeroes = compute_duration_coverage(with_zeroes, turbine_events, compute_difference_5112=True)\n",
        "\n",
        "without_zeroes = curtailments_without_zeroes.copy()\n",
        "stats_no_zeroes = compute_duration_coverage(without_zeroes, turbine_events)\n",
        "\n",
        "stats_no_curtailment = compute_duration_coverage(with_zeroes, turbine_events, filter_known_curtailment=True)"
      ],
      "id": "JW2rRfplIR3s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj1bezkyO-yo"
      },
      "source": [
        "ranking_zero = stats_zeroes.sort_values(by=['total_coverage_ratio'], ascending=False)\n",
        "ranking_non_zero = stats_no_zeroes.sort_values(by=['total_coverage_ratio'], ascending=False)\n",
        "ranking_non_curtailed = stats_no_curtailment.sort_values(by=['total_coverage_ratio'], ascending=False)\n",
        "\n",
        "ranking_zero['rank'] = range(1, len(ranking_zero)+1)\n",
        "ranking_non_zero['rank'] = range(1, len(ranking_non_zero)+1)\n",
        "ranking_non_curtailed['rank'] = range(1, len(ranking_non_curtailed)+1)\n",
        "\n",
        "print(\"number of codes: \", len(ranking_non_zero))\n",
        "print(\"rank of event 5112 in dataset with filled nans: \", ranking_zero.loc[5112]['rank'], \n",
        "      \" rank in dataset with dropped nans: \", ranking_non_zero.loc[5112]['rank'], \n",
        "      \" rank in dataset with known curtailment removed: \", ranking_non_curtailed.loc[5112]['rank'])\n",
        "\n",
        "display(ranking_zero.head(25))\n",
        "display(ranking_non_zero.head(25))\n",
        "display(ranking_non_curtailed.head(25))"
      ],
      "id": "Dj1bezkyO-yo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2VDceYlKqZW"
      },
      "source": [
        "ranking_non_curtailed"
      ],
      "id": "E2VDceYlKqZW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e18MzRJmmsK0"
      },
      "source": [
        "top20 = ranking_non_curtailed.head(25).index.values\n",
        "top20"
      ],
      "id": "e18MzRJmmsK0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayetvnjozu2y"
      },
      "source": [
        "top20desc = turbine_events[turbine_events.ErrorCode.isin(top20)][['ErrorCode', 'Text']].copy()\n",
        "top20desc.ErrorCode = top20desc.ErrorCode.astype(\"category\")\n",
        "top20desc.ErrorCode.cat.set_categories(top20, inplace=True)\n",
        "top20code = top20desc.sort_values(by='ErrorCode').ErrorCode.unique()\n",
        "top20desc = top20desc.sort_values(by='ErrorCode').Text.unique()\n",
        "for i in range(len(top20desc)):\n",
        "  print(\"rank: \", i+1, \" code: \", top20code[i], \" text: \", top20desc[i])"
      ],
      "id": "ayetvnjozu2y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-TteaKYb9gR"
      },
      "source": [
        "print('median total duration of events: ', pd.Timedelta(ranking_non_curtailed.total_duration.median(), unit='s')) \n",
        "print('arithmetic mean total duration of events: ', pd.Timedelta(ranking_non_curtailed.total_duration.mean(), unit='s'))\n",
        "print('geometric mean total duration of events: ', pd.Timedelta(stats.gmean(ranking_non_curtailed.loc[:, 'total_duration'].values[ranking_non_curtailed.loc[:, 'total_duration'].values != 0]), unit='s'))\n",
        "print('harmonic mean total duration of events: ', pd.Timedelta(stats.hmean(ranking_non_curtailed.loc[:, 'total_duration'].values[ranking_non_curtailed.loc[:, 'total_duration'].values != 0]), unit='s'))\n",
        "print('geometric standard deviation total duration of events: ', pd.Timedelta(stats.gstd(ranking_non_curtailed.loc[:, 'total_duration'].values[ranking_non_curtailed.loc[:, 'total_duration'].values != 0]), unit='s'))\n",
        "print('arithmetic standard deviation total duration of events: ', pd.Timedelta(stats.tstd(ranking_non_curtailed.loc[:, 'total_duration'].values), unit='s'))\n",
        "print('Total duration of all 5112 events across all turbines: ', turbine_events[turbine_events.ErrorCode == 5112].Duration.sum())\n",
        "print('Total duration of all comm faliure events across all turbines: ', turbine_events[turbine_events.ErrorCode == -1].Duration.sum())\n",
        "\n",
        "plot_data = pd.DataFrame(data=ranking_non_curtailed.total_duration.sort_values())\n",
        "plot_data = plot_data[plot_data.total_duration != 0]\n",
        "plot_data = np.log10(plot_data)\n",
        "plot_data['rank'] = range(len(plot_data))\n",
        "display(plot_data)\n",
        "ax = sns.barplot(x='rank', y='total_duration', data=plot_data)\n",
        "ax.set(xticklabels=[])\n",
        "ax.set(ylabel=\"duration log 10 scale\")\n",
        "ax.set(xlabel=\"sorted order\")\n",
        "ax.tick_params(bottom=False)"
      ],
      "id": "U-TteaKYb9gR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHDaXQ7gFAft"
      },
      "source": [
        "covered_ratio_zeroes.sort_values(by='difference', ascending=False)"
      ],
      "id": "qHDaXQ7gFAft",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3oIz206nFYF"
      },
      "source": [
        "print('Total duration of 5112 events on turbine GDT058: ', turbine_events[(turbine_events.ErrorCode == 5112) & (turbine_events.Turbine == 'GDT058')].sort_values(by=['Duration'], ascending = False)['Duration'].sum())\n",
        "print('Of which coincideing with curtailment: ', pd.Timedelta(covered_ratio_zeroes.loc['GDT058']['covered_dur'], unit='s'))"
      ],
      "id": "-3oIz206nFYF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5I1bj4qnSlD"
      },
      "source": [
        "setpoint = SCADA_setpoint[SCADA_setpoint.Turbine == 'GDT059'].sort_values(by=['Timestamp']).set_index('Timestamp').loc['2021-02-19 09:20:00':'2021-02-19 11:00:00']\n",
        "setpoint"
      ],
      "id": "L5I1bj4qnSlD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGf9Xzsol1Dz"
      },
      "source": [
        ""
      ],
      "id": "BGf9Xzsol1Dz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8opoQ_XsU4d"
      },
      "source": [
        "Computing the coverage durations, establishing a crude ranking and investigating event code 5112 has yielded following insights:\n",
        "\n",
        "1. The **coverage ratio** method is a crude, yet **effective** tool to measure coincidence between curtailments and events. It works as followos: the sum of the fraction of the duration of each event in turbine_events that overlaps with a detected curtailment is divided by the total sum of event durations (with or without curtailment); a ratio of 1 means all events of this type happen to coincide with curtailment, a ratio of 0 means that events are always active when the turbine is at full rated power. A ranking is thus established by sorting the coverage ratios in descending order.\n",
        "2. This metrics insights in coincidence between events and curtailment are interesting, but it also yields a **useful list** events that show a **high degree of separation from curtailment**, thus possibly serving as an **indicator for good turbine performance**.\n",
        "3.   Treating missing setpoint data and 0 setpoint value as curtailment yields slight but noticeably different results than excluding those instances from the **definition of curtailment**.\n",
        "4.   Upon investigating single instances of event 5112, it seems that **setpoint lowering kicks in only sometime after event 5112**. The setpoint will therefore be at rated power for a 10-minute interval while event 5112 triggers, and then be derated in the subsequent timestamps. Some information might be lost here, due to the rounding/flooring of the timestamps.\n",
        "5. Event 5112 ranks **33th** out of 365 events (thus in the top 10%) in the duration ratio coinciding with curtailment metric for the curtailment definition treating missing data and 0 setpoint as potential curtailment. It only achieved rank **136** out of 365 when discarding missing data. This is due to 5112 highly correlating with missing data. When removing known causes for curtailment, event 5112 is to be found on spot **21** out of 365.\n",
        "6. Event **durations are** very **heterogeneous**: \n",
        "  *   Some events happen on all turbines and last for long stretches of times, whereas occurances of other events are rare, short and far between. Thus, there is a big **discrepancy between the mean (arithmetic/geometric) and the median** of the sum of the total duration across all turbines of events per event-code.\n",
        "  *   The **median duration is 2 days and 12:50 hours**, whereas the **mean duration is over 121 days**; the **geometric mean is just about 2 days**. The clearly follow a geometric ditribution.\n",
        "  *   It can be argued, that **neither of the extremes are very interesting**: events with a high total duration, such as event '-1 comm failure', are very common and have likely been investigated already; events that are rare and short, on the other hand, do not impact production very much and should therefore be de-prioritized.\n",
        "  * **The median is generally more robust to variance and outliers but more heavily influenced by skewedness**. To that end, a weighing function is applied. There are several options:\n",
        "    * Trimming or [winsorising](https://encyclopediaofmath.org/wiki/Distance-weighted_mean) values would be a very crude method that would require setting arbitrary thresholds for data.\n",
        "    * Applying a filter function used in digital filtering could instead allow for a gradual decrease in importance. Band-filters for instance.\n",
        "    * Deriving weights from a [distance-weighed estimator](https://formulasearchengine.com/wiki/Distance-weighted_estimator) or a [Mahalanobis distance](https://en.wikipedia.org/wiki/Mahalanobis_distance) could also be an option.\n",
        "\n"
      ],
      "id": "k8opoQ_XsU4d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5I48X3_0yV2"
      },
      "source": [
        "## Model functions: statistical and ML analyses"
      ],
      "id": "C5I48X3_0yV2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4b84433"
      },
      "source": [
        "def within(start1, start2, end1, end2):\n",
        "    latest = max(start1, start2)\n",
        "    earliest = min(end1, end2)\n",
        "    delta = (earliest - latest).total_seconds()\n",
        "    \n",
        "    if delta > 0:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def daily_density_events_by_mutual_information(curtailments, events, start, end, verbose=True, repeats=10):\n",
        "    \n",
        "    nrdays = (end-start).days\n",
        "    \n",
        "    codes = np.sort(events.ErrorCode.unique())\n",
        "    events = events[['From_UTC', 'To_UTC', 'ErrorCode']].to_numpy()\n",
        "    \n",
        "    x_matrix = np.zeros((nrdays, len(codes)))    \n",
        "    \n",
        "    y_vec = np.zeros((nrdays))\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"starting estimation for \", len(curtailments), ' curtailments and ', len(codes), ' event types within ', nrdays, 'days')\n",
        "    \n",
        "    for day in range(nrdays):\n",
        "        print('day: ', day)\n",
        "        for event in events:\n",
        "            if within(start+timedelta(days=day), event[0], start+timedelta(days=day+1), event[1]):\n",
        "                x_matrix[day, np.where(codes==event[2])] += 1 #increment occurence by one if it is within that day\n",
        "                if event[2] == 2:\n",
        "                    print(\"station is in error mode between: \", event[0], ' and ', event[1])\n",
        "        for cur in curtailments:\n",
        "            if within(start+timedelta(days=day), cur.start, start+timedelta(days=day+1), cur.end):\n",
        "                print('curtailment found between ', cur.start, ' and ', cur.end)\n",
        "                y_vec[day] += 1 #increment occurence by one if it is within that day\n",
        "    \n",
        "    repeater = np.zeros((len(codes), repeats))\n",
        "    for i in range(repeats): # run MI estimation several times as it is based on non-parametric k-nearest-neighbors\n",
        "        repeater[:, i] = mutual_info_classif(x_matrix, y_vec)\n",
        "    \n",
        "    result = repeater.mean(axis=1)\n",
        "    \n",
        "\n",
        "    if verbose:\n",
        "        print('successfully computed mutual information score for densities of events versus curtailment')\n",
        "        print('code labels:')\n",
        "        print(codes)\n",
        "        print('mutual information scores:')\n",
        "        print(result)\n",
        "        \n",
        "    \n",
        "    return result, codes\n",
        "\n",
        "def rate_events_by_curtailment_isolation(curtailments, events, verbose=True):\n",
        "    \n",
        "    codes = np.sort(events.ErrorCode.unique())\n",
        "    events = events[['From_UTC', 'To_UTC', 'ErrorCode']].to_numpy()\n",
        "    \n",
        "    ratios = []\n",
        "    \n",
        "    overlap = 0\n",
        "    count = 0\n",
        "    \n",
        "    for code in codes:\n",
        "        for event in events:\n",
        "            if event[2] == code:\n",
        "                count += 1\n",
        "                for curtailment in curtailments: # Triple for loop: inefficient! Idea: extract time series / curt start times and search more efficiently therein\n",
        "                    if within(event[0], curtailment.start, event[1], curtailment.end):\n",
        "                        overlap += 1\n",
        "                        break\n",
        "        ratios.append(overlap/count)\n",
        "        overlap = 0\n",
        "        count = 0\n",
        "    return ratios, codes\n",
        "\n",
        "def rate_events_by_curtailment_isolation_advanced(curtailments, events, verbose=True, curtailmentratio=0, contemporaneity=0):\n",
        "    \n",
        "    codes = np.sort(events.ErrorCode.unique())\n",
        "    events = events[['From_UTC', 'To_UTC', 'ErrorCode']].to_numpy()\n",
        "    \n",
        "    ratios = []\n",
        "    \n",
        "    overlap = 0\n",
        "    count = 0\n",
        "    \n",
        "    for code in codes:\n",
        "        for event in events:\n",
        "            if event[2] == code:\n",
        "                count += 1\n",
        "                for curtailment in curtailments: # Triple for loop: inefficient! Idea: extract time series / curt start times and search more efficiently therein\n",
        "                    if contemporaneity == 0 or (contemporaneity == 1 and (curtailment.start==event[0] or curtailment.end==event[1])) or (contemporaneity == 2 and curtailment.start==event[0] and curtailment.end==event[1]):\n",
        "                        overlapbool, delta, ratio_curtailment_covered, ratio_event_covered = curtailment.overlappingevent(event[0], event[1])\n",
        "                        if overlapbool and ratio_curtailment_covered > curtailmentratio:\n",
        "                            overlap += ratio_event_covered\n",
        "                            break\n",
        "        ratios.append(overlap/count)\n",
        "        overlap = 0\n",
        "        count = 0\n",
        "    return ratios, codes\n",
        "        "
      ],
      "id": "a4b84433",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU-hds4y1d1O"
      },
      "source": [
        "### Execution"
      ],
      "id": "QU-hds4y1d1O"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd9268ba"
      },
      "source": [
        "mi, codes = daily_density_events_by_mutual_information(curtailmentevents, Turbine1events, pd.Timestamp('2021-03-01 00:00:00.000000'), pd.Timestamp('2021-04-01 00:00:00.000000'), verbose=True)\n",
        "\n",
        "mi2, codes2 = daily_density_events_by_mutual_information(unreported_curts, Turbine1events, pd.Timestamp('2021-03-01 00:00:00.000000'), pd.Timestamp('2021-04-01 00:00:00.000000'), verbose=True)"
      ],
      "id": "cd9268ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95c9427b"
      },
      "source": [
        "mibarplot = sns.barplot(x=codes, y=mi)\n",
        "mibarplot.set(ylim=(0, 1))"
      ],
      "id": "95c9427b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af736f79"
      },
      "source": [
        "mibarplot = sns.barplot(x=codes2, y=mi2)\n",
        "mibarplot.set(ylim=(0, 1))"
      ],
      "id": "af736f79",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "256ecaba"
      },
      "source": [
        "ratios, codes3 = rate_events_by_curtailment_isolation(unreported_curts, Turbine1events, verbose=True)\n",
        "\n",
        "overlapbarplot = sns.barplot(x=codes3, y=ratios)\n",
        "overlapbarplot.set(ylim=(0, 1))"
      ],
      "id": "256ecaba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "266f83b7"
      },
      "source": [
        "plt.scatter(turbine1['StartTime'], turbine1['WTUR11_WSpt_val_max'])\n",
        "#plt.scatter(dfcur['From_Local'], 3600)\n",
        "plt.show()"
      ],
      "id": "266f83b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b28dfab5"
      },
      "source": [
        "tmstmp = datetime.fromisoformat(\"2021-03-29 15:14:32\")\n",
        "tmstmp.second"
      ],
      "id": "b28dfab5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f4acd18"
      },
      "source": [
        "plt.scatter(park_curtailments['timestamp'], park_curtailments['setpoint_value_mean'])\n",
        "#plt.scatter(dfcur['From_Local'], 3600)\n",
        "plt.show()"
      ],
      "id": "7f4acd18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "add0d4c2"
      },
      "source": [
        ""
      ],
      "id": "add0d4c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3481f20"
      },
      "source": [
        ""
      ],
      "id": "e3481f20",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcn5tbaT0Gim"
      },
      "source": [
        "## Park curtailment"
      ],
      "id": "zcn5tbaT0Gim"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53d0a1ab"
      },
      "source": [
        "def SCADA_to_timeseries(scada: pd.DataFrame, assume_normal_operation=True):\n",
        "    \"\"\"Create a timeseries DataFrame for the setpoint signal\n",
        "\n",
        "    Args:\n",
        "        scada: DataFrame containing the scada data in tag form.\n",
        "        assume_normal_operation: if \"Setpoint\", NaN values will be set to \n",
        "        max power, else it is backfilled with the next non-NaN value.\n",
        "        !!!Don't use for wind SCADA!!!\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with setpoint arranged as time series\n",
        "    \"\"\"\n",
        "    \n",
        "    if assume_normal_operation:\n",
        "      max_val = scada['Value'].max()\n",
        "      scada = scada.pivot_table(index=['Timestamp'], columns=['Turbine']).fillna(max_val)\n",
        "    else:\n",
        "      scada = scada.pivot_table(index=['Timestamp'], columns=['Turbine']).fillna(method='bfill')\n",
        "    \n",
        "    return scada\n",
        "\n",
        "\n",
        "\n",
        "def park_curtailment(SCADA_setpoint: pd.DataFrame, curtailment_reports: pd.DataFrame, turbine_events: pd.DataFrame, SCADA_windspeed: pd.DataFrame, difference_ratio=0.1) :\n",
        "    # TODO: fix second half of function with updated turbine functions\n",
        "    \"\"\"Create a timeseries DataFrame containing all relevant information per \n",
        "    timestamp.\n",
        "\n",
        "    Args:\n",
        "        SCADA_setpoint: DataFrame containing the setpoint signal\n",
        "        curtailment_reports: DataFrame containing the curtailment reports\n",
        "        turbine_events: DataFrame containing turbine events\n",
        "        SCADA_windspeed: DataFrame containing SCADA data about wind speeds\n",
        "        difference_ratio: factor used to determine how much oscillation is \n",
        "        to be considered a new curtailment instance \n",
        "\n",
        "    Returns:\n",
        "        DataFrame with aggregated park information about curtailment\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #Set up data\n",
        "\n",
        "    turbine_events = eventdf[['From_UTC', 'To_UTC', 'ErrorCode']]  \n",
        "    SCADA_setpoint = df[['Timestamp', 'Turbine', 'Value', 'Tag']]\n",
        "    curtailment_reports = dfcur[['From_Local', 'To_Local', 'Category']]\n",
        "\n",
        "    maxval = df['Value'].max()\n",
        "    \n",
        "    setpoint_timeseries = setpoint_to_timeseries(SCADA_setpoint)\n",
        "\n",
        "    #Add minum and mean values of setpoint\n",
        "\n",
        "    park_curtailment = pd.DataFrame(index=thing.index)\n",
        "    park_curtailment['setpoint_value_mean'] = thing.mean(axis=1)\n",
        "    park_curtailment['setpoint_min'] = thing.min(axis=1)\n",
        "\n",
        "\n",
        "    turbine_curtailments = []\n",
        "\n",
        "    # Fix from here\n",
        "    break\n",
        "\n",
        "    park_curtailments = pd.DataFrame(columns=['timestamp', 'setpoint_value_mean', 'setpoint_min', 'reported_curtailment_active', 'affected_turbines', 'hwrt_likely', 'technician_likely', 'events_overlapping_curtailment', 'curtailemnt_coverage', 'event_coverage'])\n",
        "    \n",
        "    percent_done = 0 \n",
        "    print(\"computing turbine curtailment\")\n",
        "    out = display(progress(0, 100), display_id=True)\n",
        "    for turbine in turbinelist:\n",
        "        prc = round(((percent_done/len(turbinelist))*100), 2)\n",
        "        percent_done += 1\n",
        "        out.update(progress(prc, 100))  \n",
        "        turbine_curtailments.append(extract_curtailment_windows_from_setpoint(df[df['Turbine']==turbine], winddf[winddf['Turbine']==turbine], lag=lag, difference_ratio=difference_ratio))\n",
        "    \n",
        "    \n",
        "    percent_done = 0 \n",
        "    \n",
        "\n",
        "    print(\"computing park curtailment\")\n",
        "    out = display(progress(0, 100), display_id=True)\n",
        "\n",
        "    for timestamp in timeseries:\n",
        "     \n",
        "        #print(\"percent done: \", (round(percent_done/len(timeseries))*100), '%')\n",
        "        prc = round(((percent_done/len(timeseries))*100), 2)\n",
        "        print(\"\\r percent done: \", prc, \"%\")\n",
        "        percent_done += 1\n",
        "        out.update(progress(prc, 100))  \n",
        "        \n",
        "        affected_turbines = []\n",
        "        valsum = 0\n",
        "        minval = maxval\n",
        "        active = 'None'\n",
        "        prevval = maxval\n",
        "        \n",
        "        overlap_codes = [] # collect turbine events for all turbines that have active curtailment\n",
        "        ratio_curt = []\n",
        "        ratio_evt = []            \n",
        "        \n",
        "        # If any turbine experiences technician curtailment or hwrt, add it as likely cause\n",
        "        technician = False\n",
        "        hwrt = False\n",
        "        \n",
        "        for turbine in turbinelist: # three nested for loops -> needs to be more efficient\n",
        "            if len(df.loc[(df['Turbine'] == turbine) & (df['Timestamp'] == timestamp)]) == 0:\n",
        "                val = prevval \n",
        "            else:\n",
        "                val = df.loc[(df['Turbine'] == turbine) & (df['Timestamp'] == timestamp)]['Value'].item()\n",
        "                prevval = val\n",
        "            \n",
        "\n",
        "            \n",
        "            if val < maxval: # Only loop if setpoint derated\n",
        "                affected_turbines.append(turbine)\n",
        "                i, = np.where(turbinelist==turbine)\n",
        "                curts = turbine_curtailments[i[0]]\n",
        "                active_curt = None\n",
        "                for curt in curts:\n",
        "                    if during(curt.start, curt.end, timestamp):\n",
        "                        active_curt = curt # curtailment active during this timestamp\n",
        "                        if curt.text == \"technician curtailment\":\n",
        "                            technician = True\n",
        "                        if curt.text == \"hwrt\":\n",
        "                            hwrt = True\n",
        "                            \n",
        "                if active_curt != None:\n",
        "                    for event in eventdf[eventdf['Unit'] == turbine][['From_UTC', 'To_UTC', 'ErrorCode']].to_numpy() : # originally this loop was nested, but since curtailment, as defined previously, is not overlapping for a turbine, this can be sequential\n",
        "                        overlapbool, delta, ratio_curtailment_covered, ratio_event_covered = active_curt.overlappingevent(event[0], event[1])\n",
        "                        if overlapbool:\n",
        "                            overlap_codes.append(event[2])\n",
        "                            ratio_curt.append(round(ratio_curtailment_covered, 4)) # round to 4 digits for better visibility, more are not needed\n",
        "                            ratio_evt.append(round(ratio_event_covered, 4))\n",
        "            \n",
        "                \n",
        "        for curtailment in dfcur.iloc():\n",
        "            if during(curtailment['From_Local'], curtailment['To_Local'], timestamp):\n",
        "                active = curtailment['Category']\n",
        "            \n",
        "        s = pd.Series({'timestamp': timestamp, 'reported_curtailment_active' : active, 'affected_turbines': affected_turbines, 'hwrt_likely': hwrt, 'technician_likely': technician, 'events_overlapping_curtailment': overlap_codes, 'curtailemnt_coverage': ratio_curt, 'event_coverage': ratio_evt})\n",
        "        park_curtailments = park_curtailments.append(s, ignore_index=True)\n",
        "        \n",
        "    return park_curtailments, turbine_curtailments, turbinelist\n",
        "    "
      ],
      "id": "53d0a1ab",
      "execution_count": null,
      "outputs": []
    }
  ]
}